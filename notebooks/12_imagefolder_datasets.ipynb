{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageFolder Dataset Support\n",
    "\n",
    "This notebook demonstrates slipstream's support for ImageFolder-style datasets.\n",
    "\n",
    "**Supported formats:**\n",
    "- Local ImageFolder directories (torchvision-style class subdirectories)\n",
    "- S3 tar archives (auto-download, hash, and extract)\n",
    "- Automatic format detection via `SlipstreamDataset`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Creation from S3 Tar Archive\n",
    "\n",
    "The easiest way to load an ImageFolder dataset is via `SlipstreamDataset`, which auto-detects the format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream import SlipstreamDataset, SlipstreamImageFolder\n",
    "\n",
    "# Load ImageNet validation set from S3 tar archive\n",
    "# This will automatically:\n",
    "# 1. Download the tar file to local cache\n",
    "# 2. Compute SHA256 hash for deduplication\n",
    "# 3. Extract to cache directory\n",
    "# 4. Return a SlipstreamImageFolder instance\n",
    "\n",
    "dataset = SlipstreamDataset(\n",
    "    remote_dir=\"s3://visionlab-datasets/imagenet1k-raw/val.tar.gz\",\n",
    "    decode_images=False\n",
    ")\n",
    "\n",
    "print(f\"Dataset type: {type(dataset).__name__}\")\n",
    "print(f\"Is SlipstreamImageFolder: {isinstance(dataset, SlipstreamImageFolder)}\")\n",
    "print(f\"Number of samples: {len(dataset):,}\")\n",
    "print(f\"Number of classes: {len(dataset.classes)}\")\n",
    "print(f\"Field types: {dataset.field_types}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import PIL\n",
    "\n",
    "# Inspect a sample\n",
    "sample = dataset[0]\n",
    "\n",
    "print(f\"Sample keys: {list(sample.keys())}\")\n",
    "print(f\"Label: {sample['label']} ({dataset.classes[sample['label']]})\")\n",
    "print(f\"Index: {sample['index']}\")\n",
    "print(f\"Path: {sample['path']}\")\n",
    "\n",
    "if isinstance(sample['image'],(PIL.Image.Image)):\n",
    "    display(sample['image'])\n",
    "else:\n",
    "    print(f\"Image bytes (first 20): {sample['image'][:20]}...\")\n",
    "    print(f\"Image size: {len(sample['image']):,} bytes\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View a few class names\n",
    "print(\"First 10 classes:\")\n",
    "for i, cls in enumerate(dataset.classes[:10]):\n",
    "    print(f\"  {i}: {cls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Alternative Creation Methods\n",
    "\n",
    "### Using open_imagefolder() explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream import open_imagefolder\n",
    "\n",
    "# Explicit creation (same result, more control)\n",
    "dataset = open_imagefolder(\n",
    "    \"s3://visionlab-datasets/imagenet1k-raw/val.tar.gz\",\n",
    "    # cache_dir=\"/custom/cache/path\",  # Optional: override cache location\n",
    ")\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using input_dir parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also works with input_dir\n",
    "dataset = SlipstreamDataset(\n",
    "    input_dir=\"s3://visionlab-datasets/imagenet1k-raw/val.tar.gz\"\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(dataset):,} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset Type Detection\n",
    "\n",
    "Slipstream can auto-detect the dataset format from paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream.dataset import detect_local_dataset_type, is_imagefolder_structure\n",
    "\n",
    "# After extraction, check the local path\n",
    "local_path = dataset._root_path\n",
    "print(f\"Local extracted path: {local_path}\")\n",
    "\n",
    "# Check detection\n",
    "dataset_type = detect_local_dataset_type(local_path)\n",
    "print(f\"Detected type: {dataset_type}\")\n",
    "\n",
    "# Check structure\n",
    "is_imagefolder = is_imagefolder_structure(local_path)\n",
    "print(f\"Is ImageFolder structure: {is_imagefolder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DataLoader Creation\n",
    "\n",
    "### Option A: SlipstreamLoader (high-performance training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream import SlipstreamLoader, DecodeCenterCrop, ToTorchImage, Normalize\n",
    "\n",
    "# Create high-performance loader with decode pipeline\n",
    "loader = SlipstreamLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    pipelines={\n",
    "        \"image\": [\n",
    "            DecodeCenterCrop(size=224),  # Decode + center crop\n",
    "        ]\n",
    "    },\n",
    "    force_rebuild=True,\n",
    ")\n",
    "\n",
    "print(f\"Loader batches: {len(loader):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through batches\n",
    "for batch in loader:\n",
    "    print(f\"Batch keys: {list(batch.keys())}\")\n",
    "    print(f\"Image shape: {batch['image'].shape}\")  # [B, C, H, W]\n",
    "    print(f\"Image dtype: {batch['image'].dtype}\")\n",
    "    print(f\"Labels: {batch['label'][:8].tolist()}...\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B: SlipstreamLoader with Training Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream import DecodeRandomResizedCrop\n",
    "from slipstream.transforms import RandomHorizontalFlip, RandomColorJitterHSV\n",
    "\n",
    "# Create training loader with augmentations\n",
    "train_loader = SlipstreamLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    pipelines={\n",
    "        \"image\": [\n",
    "            DecodeRandomResizedCrop(size=224, scale=(0.08, 1.0)),\n",
    "            ToTorchImage(device=\"cpu\"),\n",
    "            RandomHorizontalFlip(p=0.5),\n",
    "            RandomColorJitterHSV(value=0.4, contrast=0.4, saturation=0.2, hue=0.1),\n",
    "        ]\n",
    "    },\n",
    ")\n",
    "\n",
    "# Get a batch\n",
    "batch = next(iter(train_loader))\n",
    "print(f\"Training batch shape: {batch['image'].shape}\")\n",
    "print(f\"Value range: [{batch['image'].min():.2f}, {batch['image'].max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomColorJitterHSV?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option C: Using Pipeline Presets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream.pipelines import supervised_train, supervised_val\n",
    "\n",
    "# Validation loader with preset\n",
    "val_loader = SlipstreamLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    pipelines=supervised_val(size=224, device=\"cpu\"),\n",
    ")\n",
    "\n",
    "batch = next(iter(val_loader))\n",
    "print(f\"Val batch shape: {batch['image'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loader with preset\n",
    "train_loader = SlipstreamLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    pipelines=supervised_train(size=224, seed=42, device=\"cpu\"),\n",
    ")\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "print(f\"Train batch shape: {batch['image'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Some Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from slipstream import decode_image\n",
    "\n",
    "# Get a few samples\n",
    "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    sample = dataset[i * 100]  # Sample every 100th image\n",
    "    img = decode_image(sample['image'], to_pil=True)\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(f\"{dataset.classes[sample['label']][:15]}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Dataset Creation:**\n",
    "```python\n",
    "# Auto-detection (recommended)\n",
    "dataset = SlipstreamDataset(remote_dir=\"s3://bucket/data.tar.gz\")\n",
    "dataset = SlipstreamDataset(local_dir=\"/path/to/imagefolder\")\n",
    "\n",
    "# Explicit\n",
    "dataset = open_imagefolder(\"s3://bucket/data.tar.gz\")\n",
    "dataset = SlipstreamImageFolder(\"/path/to/imagefolder\")\n",
    "```\n",
    "\n",
    "**DataLoader Creation:**\n",
    "```python\n",
    "# High-performance training\n",
    "loader = SlipstreamLoader(\n",
    "    dataset,\n",
    "    batch_size=256,\n",
    "    pipelines=supervised_train(224, device=\"cuda\"),\n",
    ")\n",
    "\n",
    "# Simple iteration\n",
    "loader = DataLoader(dataset, batch_size=32, collate_fn=list_collate_fn)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
