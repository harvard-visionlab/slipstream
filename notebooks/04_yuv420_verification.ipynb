{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JPEG vs YUV420 Visual Verification\n",
    "\n",
    "Head-to-head comparison of the JPEG and YUV420 image formats in `SlipstreamLoader`.\n",
    "\n",
    "YUV420 stores decoded images as raw planar YUV 4:2:0 (chroma subsampled), eliminating\n",
    "JPEG Huffman decode + IDCT at load time. The round-trip (JPEG → RGB → YUV420P → RGB)\n",
    "introduces small pixel-level errors from chroma subsampling. This notebook verifies\n",
    "the outputs are visually identical and quantifies the pixel differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LITDATA_VAL_PATH = \"s3://visionlab-datasets/imagenet1k/pre-processed/s256-l512-jpgbytes-q100-streaming/val/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from slipstream import SlipstreamDataset, SlipstreamLoader, DecodeCenterCrop\n",
    "\n",
    "dataset = SlipstreamDataset(\n",
    "    remote_dir=LITDATA_VAL_PATH,\n",
    "    decode_images=False,\n",
    ")\n",
    "print(f\"Dataset: {len(dataset):,} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the same batch with JPEG and YUV420\n",
    "\n",
    "We use `CenterCrop(224)` with `shuffle=False` so both formats decode the exact same\n",
    "images with the same deterministic crop.\n",
    "\n",
    "**Note:** The first time `image_format=\"yuv420\"` is used, the loader builds a YUV420\n",
    "sibling cache by decoding all JPEG images and converting them to YUV420P format.\n",
    "This is a one-time operation that takes a few minutes for 50k images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: First run with image_format=\"yuv420\" triggers a one-time cache build\n",
    "# that converts all JPEGs to YUV420 format. This takes a few minutes.\n",
    "\n",
    "def load_batch(image_format, verbose=True):\n",
    "    loader = SlipstreamLoader(\n",
    "        dataset,\n",
    "        batch_size=16,\n",
    "        shuffle=False,\n",
    "        image_format=image_format,\n",
    "        pipelines={'image': [DecodeCenterCrop(224)]},\n",
    "        exclude_fields=['path'],\n",
    "        verbose=verbose,\n",
    "    )\n",
    "    batch = next(iter(loader))\n",
    "    loader.shutdown()\n",
    "    return batch\n",
    "\n",
    "batch_jpeg = load_batch(\"jpeg\", verbose=False)\n",
    "batch_yuv = load_batch(\"yuv420\", verbose=True)  # verbose=True shows YUV420 cache build progress\n",
    "\n",
    "img_jpeg = batch_jpeg['image']  # [B, H, W, C] uint8\n",
    "img_yuv = batch_yuv['image']\n",
    "print(f\"JPEG:   {img_jpeg.shape}, dtype={img_jpeg.dtype}\")\n",
    "print(f\"YUV420: {img_yuv.shape}, dtype={img_yuv.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Side-by-side comparison\n",
    "\n",
    "Top row: JPEG decode. Bottom row: YUV420 decode. Should look identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 8\n",
    "fig, axes = plt.subplots(2, n, figsize=(n * 1.8, 3.8))\n",
    "for i in range(n):\n",
    "    axes[0][i].imshow(img_jpeg[i])  # Already HWC numpy\n",
    "    axes[0][i].axis('off')\n",
    "    axes[1][i].imshow(img_yuv[i])  # Already HWC numpy\n",
    "    axes[1][i].axis('off')\n",
    "axes[0][0].set_ylabel('JPEG', fontsize=11)\n",
    "axes[1][0].set_ylabel('YUV420', fontsize=11)\n",
    "fig.suptitle('CenterCrop(224): JPEG vs YUV420', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pixel-level difference analysis\n",
    "\n",
    "The YUV420 round-trip (RGB → YUV420P → RGB) introduces errors from:\n",
    "1. **Chroma subsampling** — U/V planes are half-resolution (2x2 block averaging), which\n",
    "   permanently discards color detail. At sharp color edges (e.g., a bright object against\n",
    "   a contrasting background), the averaged chroma is wrong for pixels on both sides of the\n",
    "   edge, causing large errors in individual pixels.\n",
    "2. **Fixed-point BT.601 conversion** — integer rounding in both directions adds ±1.\n",
    "\n",
    "Typical results: mean ~5, median ~2, with most pixels within ±5. Outliers up to ~150 occur\n",
    "at sharp color edges where subsampled chroma overshoots in one channel. This is the same\n",
    "error profile as JPEG 4:2:0 and all video codecs (H.264, H.265). For vision model training,\n",
    "these errors are negligible compared to standard augmentations (random crop, color jitter, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy HWC to torch for numerical analysis\n",
    "img_jpeg_t = torch.from_numpy(img_jpeg).permute(0, 3, 1, 2)  # HWC -> CHW\n",
    "img_yuv_t = torch.from_numpy(img_yuv).permute(0, 3, 1, 2)\n",
    "diff = (img_jpeg_t.float() - img_yuv_t.float()).abs()\n",
    "\n",
    "print(f\"Pixel difference statistics (across entire batch):\")\n",
    "print(f\"  Mean absolute error:  {diff.mean():.3f}\")\n",
    "print(f\"  Max absolute error:   {diff.max():.0f}\")\n",
    "print(f\"  Median:               {diff.median():.0f}\")\n",
    "print(f\"  % pixels with diff=0: {(diff == 0).float().mean() * 100:.1f}%\")\n",
    "print(f\"  % pixels with diff≤1: {(diff <= 1).float().mean() * 100:.1f}%\")\n",
    "print(f\"  % pixels with diff≤2: {(diff <= 2).float().mean() * 100:.1f}%\")\n",
    "print(f\"  % pixels with diff>5: {(diff > 5).float().mean() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show difference heatmap for first 4 images\n",
    "fig, axes = plt.subplots(3, 4, figsize=(9, 7))\n",
    "for i in range(4):\n",
    "    axes[0][i].imshow(img_jpeg[i])  # Already HWC numpy\n",
    "    axes[0][i].set_title(f'JPEG #{i}', fontsize=9)\n",
    "    axes[0][i].axis('off')\n",
    "\n",
    "    axes[1][i].imshow(img_yuv[i])  # Already HWC numpy\n",
    "    axes[1][i].set_title(f'YUV420 #{i}', fontsize=9)\n",
    "    axes[1][i].axis('off')\n",
    "\n",
    "    # Per-pixel max diff across channels (use torch tensor computed above)\n",
    "    pixel_diff = diff[i].max(dim=0).values.numpy()\n",
    "    im = axes[2][i].imshow(pixel_diff, cmap='hot', vmin=0, vmax=5)\n",
    "    axes[2][i].set_title(f'|diff| (max={pixel_diff.max():.0f})', fontsize=9)\n",
    "    axes[2][i].axis('off')\n",
    "\n",
    "fig.colorbar(im, ax=axes[2], shrink=0.8, label='Pixel difference')\n",
    "fig.suptitle('Pixel-level difference: JPEG vs YUV420', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of per-pixel differences\n",
    "fig, ax = plt.subplots(figsize=(7, 3.5))\n",
    "values = diff.flatten().numpy()\n",
    "max_val = int(values.max())\n",
    "counts, bins, _ = ax.hist(values, bins=np.arange(-0.5, max_val + 1.5, 1),\n",
    "                          edgecolor='black', linewidth=0.5)\n",
    "ax.set_xlabel('Absolute pixel difference')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Distribution of per-pixel errors (JPEG vs YUV420)', fontweight='bold')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlim(-0.5, max_val + 0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (uv auto)",
   "language": "python",
   "name": "python-uv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
