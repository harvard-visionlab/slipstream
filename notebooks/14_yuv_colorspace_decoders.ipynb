{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YUV Colorspace Decoders\n",
    "\n",
    "This notebook demonstrates the YUV-output decoder stages that keep images in YUV colorspace\n",
    "rather than converting to RGB. These are useful for:\n",
    "\n",
    "1. **Cross-channel contrastive learning** (e.g., Isola's colorization work) where Y, U, V\n",
    "   channels are treated as separate prediction targets\n",
    "2. **Perceptual loss** using luminance (Y channel) for structure\n",
    "3. **Research** on color-blind or luminance-only models\n",
    "\n",
    "## Available Stages\n",
    "\n",
    "| Stage | Output | Description |\n",
    "|-------|--------|-------------|\n",
    "| `DecodeYUVFullRes` | List of `[H,W,3]` | Full image, variable size, YUV colorspace |\n",
    "| `DecodeYUVPlanes` | List of `(Y, U, V)` tuples | Raw planes at native resolution (Y: HxW, U/V: H/2 x W/2) |\n",
    "| `DecodeYUVCenterCrop` | `[B,H,W,3]` | Center crop, fixed size, YUV colorspace |\n",
    "| `DecodeYUVRandomResizedCrop` | `[B,H,W,3]` | Random resized crop, fixed size, YUV colorspace |\n",
    "| `DecodeYUVResizeCrop` | `[B,H,W,3]` | Resize + center crop, fixed size, YUV colorspace |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LITDATA_VAL_PATH = \"s3://visionlab-datasets/imagenet1k/pre-processed/s256-l512-jpgbytes-q100-streaming/val/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from slipstream import SlipstreamDataset, SlipstreamLoader\n",
    "from slipstream.decoders import (\n",
    "    # RGB output (standard)\n",
    "    DecodeCenterCrop,\n",
    "    DecodeRandomResizedCrop,\n",
    "    # YUV output (keeps colorspace)\n",
    "    DecodeYUVCenterCrop,\n",
    "    DecodeYUVRandomResizedCrop,\n",
    "    DecodeYUVResizeCrop,\n",
    "    DecodeYUVFullRes,\n",
    "    DecodeYUVPlanes,\n",
    ")\n",
    "\n",
    "dataset = SlipstreamDataset(\n",
    "    remote_dir=LITDATA_VAL_PATH,\n",
    "    decode_images=False,\n",
    ")\n",
    "print(f\"Dataset: {len(dataset):,} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper: Visualize YUV images\n",
    "\n",
    "YUV images have channels (Y=luminance, U=blue-difference, V=red-difference).\n",
    "To display them, we either:\n",
    "1. Convert back to RGB for viewing\n",
    "2. Show each channel separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yuv_to_rgb(yuv: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Convert YUV [H,W,3] uint8 to RGB [H,W,3] uint8.\n",
    "    \n",
    "    Uses BT.601 conversion matrix (same as JPEG/FFMPEG).\n",
    "    \"\"\"\n",
    "    yuv = yuv.astype(np.float32)\n",
    "    y, u, v = yuv[..., 0], yuv[..., 1] - 128, yuv[..., 2] - 128\n",
    "    \n",
    "    r = y + 1.402 * v\n",
    "    g = y - 0.344136 * u - 0.714136 * v\n",
    "    b = y + 1.772 * u\n",
    "    \n",
    "    rgb = np.stack([r, g, b], axis=-1)\n",
    "    return np.clip(rgb, 0, 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def show_yuv_channels(yuv: np.ndarray, title: str = \"\"):\n",
    "    \"\"\"Display Y, U, V channels and RGB reconstruction.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(12, 3))\n",
    "    \n",
    "    axes[0].imshow(yuv[..., 0], cmap='gray')\n",
    "    axes[0].set_title('Y (Luminance)')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(yuv[..., 1], cmap='coolwarm', vmin=0, vmax=255)\n",
    "    axes[1].set_title('U (Blue-diff)')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    axes[2].imshow(yuv[..., 2], cmap='coolwarm', vmin=0, vmax=255)\n",
    "    axes[2].set_title('V (Red-diff)')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    axes[3].imshow(yuv_to_rgb(yuv))\n",
    "    axes[3].set_title('RGB (converted)')\n",
    "    axes[3].axis('off')\n",
    "    \n",
    "    if title:\n",
    "        fig.suptitle(title, fontsize=12, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecodeYUVCenterCrop vs DecodeCenterCrop\n",
    "\n",
    "Compare RGB output (standard) with YUV output (keeps colorspace)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load same images with RGB and YUV decoders\n",
    "def load_batch(pipeline, image_format=\"yuv420\"):\n",
    "    loader = SlipstreamLoader(\n",
    "        dataset,\n",
    "        batch_size=8,\n",
    "        shuffle=False,\n",
    "        image_format=image_format,\n",
    "        pipelines={'image': [pipeline]},\n",
    "        exclude_fields=['path'],\n",
    "        verbose=False,\n",
    "    )\n",
    "    batch = next(iter(loader))\n",
    "    loader.shutdown()\n",
    "    return batch['image']\n",
    "\n",
    "# RGB output (standard decoder)\n",
    "rgb_images = load_batch(DecodeCenterCrop(224))\n",
    "print(f\"RGB output: {rgb_images.shape}\")\n",
    "\n",
    "# YUV output (keeps colorspace)\n",
    "yuv_images = load_batch(DecodeYUVCenterCrop(224))\n",
    "print(f\"YUV output: {yuv_images.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first image: RGB vs YUV channels\n",
    "fig, axes = plt.subplots(2, 4, figsize=(14, 6))\n",
    "\n",
    "# Top row: RGB image shown as RGB and split into R, G, B\n",
    "rgb = rgb_images[0]  # [H, W, 3]\n",
    "axes[0, 0].imshow(rgb)\n",
    "axes[0, 0].set_title('RGB (full)')\n",
    "axes[0, 1].imshow(rgb[..., 0], cmap='Reds')\n",
    "axes[0, 1].set_title('R channel')\n",
    "axes[0, 2].imshow(rgb[..., 1], cmap='Greens')\n",
    "axes[0, 2].set_title('G channel')\n",
    "axes[0, 3].imshow(rgb[..., 2], cmap='Blues')\n",
    "axes[0, 3].set_title('B channel')\n",
    "\n",
    "# Bottom row: YUV image shown as converted RGB and split into Y, U, V\n",
    "yuv = yuv_images[0]  # [H, W, 3]\n",
    "axes[1, 0].imshow(yuv_to_rgb(yuv))\n",
    "axes[1, 0].set_title('YUV→RGB')\n",
    "axes[1, 1].imshow(yuv[..., 0], cmap='gray')\n",
    "axes[1, 1].set_title('Y (luminance)')\n",
    "axes[1, 2].imshow(yuv[..., 1], cmap='coolwarm', vmin=0, vmax=255)\n",
    "axes[1, 2].set_title('U (blue-diff)')\n",
    "axes[1, 3].imshow(yuv[..., 2], cmap='coolwarm', vmin=0, vmax=255)\n",
    "axes[1, 3].set_title('V (red-diff)')\n",
    "\n",
    "for ax in axes.flat:\n",
    "    ax.axis('off')\n",
    "\n",
    "axes[0, 0].set_ylabel('DecodeCenterCrop\\n(RGB output)', fontsize=10)\n",
    "axes[1, 0].set_ylabel('DecodeYUVCenterCrop\\n(YUV output)', fontsize=10)\n",
    "\n",
    "fig.suptitle('RGB vs YUV Decoder Output', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecodeYUVRandomResizedCrop\n",
    "\n",
    "Random crops in YUV colorspace for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yuv_rrc = load_batch(DecodeYUVRandomResizedCrop(224, seed=42))\n",
    "print(f\"YUV RRC output: {yuv_rrc.shape}\")\n",
    "\n",
    "# Show multiple crops\n",
    "n = 4\n",
    "fig, axes = plt.subplots(n, 4, figsize=(12, n * 2.5))\n",
    "\n",
    "for i in range(n):\n",
    "    yuv = yuv_rrc[i]\n",
    "    axes[i, 0].imshow(yuv_to_rgb(yuv))\n",
    "    axes[i, 0].set_title('RGB' if i == 0 else '')\n",
    "    axes[i, 1].imshow(yuv[..., 0], cmap='gray')\n",
    "    axes[i, 1].set_title('Y' if i == 0 else '')\n",
    "    axes[i, 2].imshow(yuv[..., 1], cmap='coolwarm', vmin=0, vmax=255)\n",
    "    axes[i, 2].set_title('U' if i == 0 else '')\n",
    "    axes[i, 3].imshow(yuv[..., 2], cmap='coolwarm', vmin=0, vmax=255)\n",
    "    axes[i, 3].set_title('V' if i == 0 else '')\n",
    "\n",
    "for ax in axes.flat:\n",
    "    ax.axis('off')\n",
    "\n",
    "fig.suptitle('DecodeYUVRandomResizedCrop(224)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecodeYUVResizeCrop (Validation Transform)\n",
    "\n",
    "Standard ImageNet validation: resize shortest edge to 256, center crop 224."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yuv_val = load_batch(DecodeYUVResizeCrop(resize_size=256, crop_size=224))\n",
    "print(f\"YUV ResizeCrop output: {yuv_val.shape}\")\n",
    "\n",
    "# Show a few samples\n",
    "fig, axes = plt.subplots(2, 4, figsize=(12, 5))\n",
    "for i in range(4):\n",
    "    yuv = yuv_val[i]\n",
    "    axes[0, i].imshow(yuv_to_rgb(yuv))\n",
    "    axes[0, i].axis('off')\n",
    "    axes[1, i].imshow(yuv[..., 0], cmap='gray')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "axes[0, 0].set_ylabel('RGB view', fontsize=10)\n",
    "axes[1, 0].set_ylabel('Y channel', fontsize=10)\n",
    "fig.suptitle('DecodeYUVResizeCrop(256, 224)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case: Cross-Channel Prediction\n",
    "\n",
    "For colorization or cross-channel contrastive learning, you can use Y as input\n",
    "and U, V as prediction targets (or vice versa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Split YUV into separate channels for model input/target\n",
    "yuv_batch = yuv_rrc  # [B, H, W, 3]\n",
    "\n",
    "# For colorization: predict color (U, V) from grayscale (Y)\n",
    "luminance = yuv_batch[..., 0:1]  # [B, H, W, 1]\n",
    "chrominance = yuv_batch[..., 1:3]  # [B, H, W, 2]\n",
    "\n",
    "print(f\"Luminance (input):    {luminance.shape}\")\n",
    "print(f\"Chrominance (target): {chrominance.shape}\")\n",
    "\n",
    "# Visualize the split\n",
    "fig, axes = plt.subplots(1, 4, figsize=(14, 3))\n",
    "i = 0\n",
    "axes[0].imshow(yuv_to_rgb(yuv_batch[i]))\n",
    "axes[0].set_title('Original (YUV→RGB)')\n",
    "axes[1].imshow(luminance[i, ..., 0], cmap='gray')\n",
    "axes[1].set_title('Input: Y (grayscale)')\n",
    "axes[2].imshow(chrominance[i, ..., 0], cmap='coolwarm', vmin=0, vmax=255)\n",
    "axes[2].set_title('Target: U')\n",
    "axes[3].imshow(chrominance[i, ..., 1], cmap='coolwarm', vmin=0, vmax=255)\n",
    "axes[3].set_title('Target: V')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.axis('off')\n",
    "fig.suptitle('Cross-Channel Prediction Setup', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channel Normalization\n",
    "\n",
    "YUV channels have different value ranges:\n",
    "- **Y** (luminance): 16-235 for video, 0-255 for full-range\n",
    "- **U, V** (chrominance): centered at 128, range ~16-240\n",
    "\n",
    "For neural network training, you may want to normalize differently than RGB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute channel statistics from a batch\n",
    "yuv_float = yuv_batch.astype(np.float32)\n",
    "\n",
    "print(\"Channel statistics:\")\n",
    "for c, name in enumerate(['Y', 'U', 'V']):\n",
    "    channel = yuv_float[..., c]\n",
    "    print(f\"  {name}: mean={channel.mean():.3f}, std={channel.std():.3f}, \"\n",
    "          f\"min={channel.min():.3f}, max={channel.max():.3f}\")\n",
    "\n",
    "print(\"\\nNote: U and V are centered around 0.5 (128/255)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute channel statistics from a batch\n",
    "yuv_float = yuv_batch.astype(np.float32) / 255.0\n",
    "\n",
    "print(\"Channel statistics (normalized 0-1):\")\n",
    "for c, name in enumerate(['Y', 'U', 'V']):\n",
    "    channel = yuv_float[..., c]\n",
    "    print(f\"  {name}: mean={channel.mean():.3f}, std={channel.std():.3f}, \"\n",
    "          f\"min={channel.min():.3f}, max={channel.max():.3f}\")\n",
    "\n",
    "print(\"\\nNote: U and V are centered around 0.5 (128/255)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream import compute_normalization_stats                                                                                                                             \n",
    "from slipstream.cache import OptimizedCache                                                                                                                                  \n",
    "\n",
    "loader = SlipstreamLoader(\n",
    "    dataset,\n",
    "    batch_size=256,\n",
    "    shuffle=False,\n",
    "    image_format=\"yuv420\",\n",
    "    pipelines={'image': [DecodeYUVCenterCrop(224)]},\n",
    "    exclude_fields=['path'],\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# Compute YUV stats (use colorspace=\"yuv\" to keep YUV instead of converting to RGB)\n",
    "yuv_stats = compute_normalization_stats(\n",
    "    loader.cache, \n",
    "    image_format=\"yuv420\", \n",
    "    colorspace=\"yuv\",  # <-- NEW: keeps YUV colorspace\n",
    "    num_samples=5000,  # subset for speed\n",
    ")\n",
    "\n",
    "# Compare with RGB stats (default behavior)\n",
    "print(\"\\nFor comparison, RGB stats (converts YUV→RGB):\")\n",
    "rgb_stats = compute_normalization_stats(\n",
    "    loader.cache, \n",
    "    image_format=\"yuv420\", \n",
    "    colorspace=\"rgb\",  # <-- default: converts to RGB\n",
    "    num_samples=5000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The `DecodeYUV*` stages provide a complete set of crop operations that output\n",
    "YUV colorspace instead of RGB:\n",
    "\n",
    "| Stage | Use Case |\n",
    "|-------|----------|\n",
    "| `DecodeYUVCenterCrop` | Validation with YUV output |\n",
    "| `DecodeYUVRandomResizedCrop` | Training with YUV output |\n",
    "| `DecodeYUVResizeCrop` | ImageNet-style validation with YUV output |\n",
    "| `DecodeYUVFullRes` | Variable-size full images in YUV |\n",
    "| `DecodeYUVPlanes` | Raw Y/U/V planes at native resolution |\n",
    "\n",
    "These are useful for:\n",
    "- Cross-channel contrastive learning (colorization, split-brain autoencoders)\n",
    "- Luminance-only processing (grayscale models using just Y channel)\n",
    "- Research on color perception and representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
