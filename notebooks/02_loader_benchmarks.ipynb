{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# SlipstreamLoader Benchmarks\n",
    "\n",
    "This notebook benchmarks the high-performance loading pipeline over **full epochs**:\n",
    "\n",
    "1. **Raw I/O**: Memory-mapped batch loading with `OptimizedCache`\n",
    "2. **Comparison**: OptimizedCache vs StreamingDataLoader (the key speedup!)\n",
    "3. **CPU Decode**: Parallel JPEG decode with TurboJPEG\n",
    "4. **Full Pipeline**: `SlipstreamLoader` with decode + transforms\n",
    "5. **Summary**: All results in one table\n",
    "\n",
    "Each stage is benchmarked for multiple complete epochs (after warmup) to ensure consistent measurements.\n",
    "\n",
    "## Performance Targets (from CLAUDE.md)\n",
    "\n",
    "| Metric | FFCV | SlipstreamLoader | Notes |\n",
    "|--------|------|------------------|-------|\n",
    "| Raw I/O | ~350k img/s | **480k+ img/s** | +37% faster |\n",
    "| GPU Decode + RRC | ~10k img/s | **10.1k img/s** | Equivalent |\n",
    "| CPU Decode + RRC | N/A | ~5.7k img/s | TurboJPEG |\n",
    "| Cold Start | baseline | **20% faster** | Parallel chunk downloads |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataset path (ImageNet validation, streaming format)\n",
    "LITDATA_VAL_PATH = \"s3://visionlab-datasets/imagenet1k/pre-processed/s256-l512-jpgbytes-q100-streaming/val/\"\n",
    "\n",
    "# Benchmark parameters\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 3      # Number of full epochs to benchmark (results averaged)\n",
    "NUM_WARMUP = 1      # Warmup epochs (not timed, important for page cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from slipstream import SlipstreamDataset, list_collate_fn  \n",
    "\n",
    "# First, ensure the dataset is cached locally\n",
    "print(\"Loading dataset to ensure cache is populated...\")\n",
    "dataset = SlipstreamDataset(\n",
    "    remote_dir=LITDATA_VAL_PATH,\n",
    "    decode_images=False,\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 1. Benchmark Raw I/O (OptimizedCache)\n",
    "\n",
    "This measures pure I/O throughput without decoding. The OptimizedCache uses:\n",
    "- Memory-mapped contiguous file format for all fields\n",
    "- Numba JIT-compiled batch loading with `nogil=True`\n",
    "- Pre-allocated buffers to avoid per-batch allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream.cache import OptimizedCache\n",
    "\n",
    "# Build/load optimized cache\n",
    "print(\"Building/loading optimized cache...\")\n",
    "cache = OptimizedCache.build(dataset) if not OptimizedCache.exists(dataset.cache_path) else OptimizedCache.load(dataset.cache_path)\n",
    "print(f\"Cache ready: {len(cache):,} samples\")\n",
    "print(f\"Fields: {list(cache.fields.keys())}\")\n",
    "cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_raw_io_epoch(cache, batch_size, field='image'):\n",
    "    \"\"\"Benchmark raw I/O throughput for one full epoch.\"\"\"\n",
    "    num_samples = len(cache)\n",
    "    num_batches = (num_samples + batch_size - 1) // batch_size\n",
    "    indices = np.arange(num_samples, dtype=np.int64)\n",
    "    \n",
    "    total_samples = 0\n",
    "    start = time.perf_counter()\n",
    "    \n",
    "    for i in tqdm(range(num_batches), leave=False):\n",
    "        batch_start = i * batch_size\n",
    "        batch_end = min(batch_start + batch_size, num_samples)\n",
    "        batch_indices = indices[batch_start:batch_end]\n",
    "        \n",
    "        # Load batch (image field)\n",
    "        batch_data = cache.load_batch(batch_indices, fields=[field])\n",
    "        total_samples += len(batch_indices)\n",
    "    \n",
    "    elapsed = time.perf_counter() - start\n",
    "    samples_per_sec = total_samples / elapsed\n",
    "    \n",
    "    return {\n",
    "        'samples_per_sec': samples_per_sec,\n",
    "        'elapsed_sec': elapsed,\n",
    "        'total_samples': total_samples,\n",
    "    }\n",
    "\n",
    "def benchmark_raw_io(cache, batch_size, num_epochs, num_warmup, field='image'):\n",
    "    \"\"\"Benchmark raw I/O over multiple epochs.\"\"\"\n",
    "    # Warmup epochs (show results)\n",
    "    print(f\"  Warmup ({num_warmup} epoch(s)):\")\n",
    "    for i in range(num_warmup):\n",
    "        result = benchmark_raw_io_epoch(cache, batch_size, field)\n",
    "        print(f\"    Warmup {i + 1}: {result['samples_per_sec']:,.0f} samples/sec ({result['elapsed_sec']:.2f}s)\")\n",
    "    \n",
    "    # Timed epochs\n",
    "    results = []\n",
    "    for epoch in range(num_epochs):\n",
    "        result = benchmark_raw_io_epoch(cache, batch_size, field)\n",
    "        results.append(result)\n",
    "        print(f\"  Epoch {epoch + 1}: {result['samples_per_sec']:,.0f} samples/sec ({result['elapsed_sec']:.2f}s)\")\n",
    "    \n",
    "    # Average results\n",
    "    avg_samples_per_sec = np.mean([r['samples_per_sec'] for r in results])\n",
    "    total_samples = results[0]['total_samples']\n",
    "    \n",
    "    return {\n",
    "        'samples_per_sec': avg_samples_per_sec,\n",
    "        'total_samples': total_samples,\n",
    "        'num_epochs': num_epochs,\n",
    "        'per_epoch_results': results,\n",
    "    }\n",
    "\n",
    "print(\"Benchmarking raw I/O (full epochs)...\\n\")\n",
    "\n",
    "# Image field (variable-size, main benchmark)\n",
    "print(\"Image field (cache.load_batch):\")\n",
    "result_io = benchmark_raw_io(cache, BATCH_SIZE, NUM_EPOCHS, NUM_WARMUP, field='image')\n",
    "print(f\"  Average: {result_io['samples_per_sec']:,.0f} samples/sec\\n\")\n",
    "\n",
    "# Label field (fixed-size, should be even faster)\n",
    "print(\"Label field (cache.load_batch):\")\n",
    "result_labels = benchmark_raw_io(cache, BATCH_SIZE, NUM_EPOCHS, NUM_WARMUP, field='label')\n",
    "print(f\"  Average: {result_labels['samples_per_sec']:,.0f} samples/sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 2. Compare: OptimizedCache vs StreamingDataLoader (Raw I/O)\n",
    "\n",
    "This is the key comparison showing why OptimizedCache matters:\n",
    "- **StreamingDataLoader**: Standard LitData iteration (sequential chunk reads)\n",
    "- **OptimizedCache**: Memory-mapped batch loading (O(1) random access)\n",
    "\n",
    "After warmup (epoch 1), the OptimizedCache benefits from OS page cache, making subsequent epochs dramatically faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from litdata import StreamingDataLoader\n",
    "from slipstream import SlipstreamLoader\n",
    "\n",
    "def benchmark_loader_epoch_raw(loader):\n",
    "    \"\"\"Benchmark loader for one full epoch (raw iteration).\"\"\"\n",
    "    total_samples = 0\n",
    "    start = time.perf_counter()\n",
    "    \n",
    "    for batch in tqdm(loader, leave=False):\n",
    "        # Just count samples - raw data\n",
    "        if isinstance(batch, dict):\n",
    "            img_data = batch.get('image')\n",
    "            if isinstance(img_data, dict):\n",
    "                # Raw dict with 'data', 'sizes', etc.\n",
    "                total_samples += len(img_data['data'])\n",
    "            elif hasattr(img_data, '__len__'):\n",
    "                total_samples += len(img_data)\n",
    "            else:\n",
    "                total_samples += batch.get('label', torch.tensor([0])).shape[0]\n",
    "        else:\n",
    "            total_samples += len(batch[0]) if isinstance(batch, (list, tuple)) else 1\n",
    "    \n",
    "    elapsed = time.perf_counter() - start\n",
    "    samples_per_sec = total_samples / elapsed if elapsed > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'samples_per_sec': samples_per_sec,\n",
    "        'elapsed_sec': elapsed,\n",
    "        'total_samples': total_samples,\n",
    "    }\n",
    "\n",
    "def benchmark_dataloader(loader, num_epochs, num_warmup, name=\"Loader\"):\n",
    "    \"\"\"Benchmark any dataloader over multiple epochs.\"\"\"\n",
    "    # Warmup epochs (show results)\n",
    "    print(f\"  Warmup ({num_warmup} epoch(s)):\")\n",
    "    for i in range(num_warmup):\n",
    "        result = benchmark_loader_epoch_raw(loader)\n",
    "        print(f\"    Warmup {i + 1}: {result['samples_per_sec']:,.0f} samples/sec ({result['elapsed_sec']:.2f}s)\")\n",
    "    \n",
    "    # Timed epochs\n",
    "    results = []\n",
    "    for epoch in range(num_epochs):\n",
    "        result = benchmark_loader_epoch_raw(loader)\n",
    "        results.append(result)\n",
    "        print(f\"  Epoch {epoch + 1}: {result['samples_per_sec']:,.0f} samples/sec ({result['elapsed_sec']:.2f}s)\")\n",
    "    \n",
    "    avg_samples_per_sec = np.mean([r['samples_per_sec'] for r in results])\n",
    "    \n",
    "    return {\n",
    "        'samples_per_sec': avg_samples_per_sec,\n",
    "        'total_samples': results[0]['total_samples'],\n",
    "        'per_epoch_results': results,\n",
    "    }\n",
    "\n",
    "print(\"Benchmarking DataLoaders HEAD-TO-HEAD (raw I/O, no decode)...\\n\")\n",
    "\n",
    "# 1. StreamingDataLoader (LitData)\n",
    "streaming_loader = StreamingDataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    drop_last=False,\n",
    "    collate_fn=list_collate_fn,  # Handle variable-sized image bytes\n",
    ")\n",
    "\n",
    "print(\"StreamingDataLoader (8 workers):\")\n",
    "result_streaming = benchmark_dataloader(streaming_loader, NUM_EPOCHS, NUM_WARMUP)\n",
    "print(f\"  Average: {result_streaming['samples_per_sec']:,.0f} samples/sec\\n\")\n",
    "\n",
    "# 2. SlipstreamLoader with NO pipelines (raw bytes)\n",
    "raw_loader = SlipstreamLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    # No pipelines = raw data!\n",
    ")\n",
    "\n",
    "print(\"SlipstreamLoader (no pipelines, raw I/O):\")\n",
    "result_slipstream_raw = benchmark_dataloader(raw_loader, NUM_EPOCHS, NUM_WARMUP)\n",
    "print(f\"  Average: {result_slipstream_raw['samples_per_sec']:,.0f} samples/sec\\n\")\n",
    "\n",
    "# Calculate speedup\n",
    "speedup = result_slipstream_raw['samples_per_sec'] / result_streaming['samples_per_sec'] if result_streaming['samples_per_sec'] > 0 else float('inf')\n",
    "print(f\"--- Result ---\")\n",
    "print(f\"SlipstreamLoader is {speedup:.1f}x faster than StreamingDataLoader for raw I/O\")\n",
    "print(f\"This is because SlipstreamLoader uses memory-mapped OptimizedCache with OS page cache.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## 3. Benchmark CPU Decode (TurboJPEG)\n",
    "\n",
    "This measures decode throughput using TurboJPEG with:\n",
    "- Thread-local decoder instances (no lock contention)\n",
    "- DCT-space cropping (lossless, ~2x faster than post-decode crop)\n",
    "- ThreadPoolExecutor parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream.decoders import CPUDecoder\n",
    "\n",
    "# Initialize decoder\n",
    "cpu_decoder = CPUDecoder(num_workers=8)\n",
    "print(f\"CPU decoder: {cpu_decoder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_cpu_decode_epoch(cache, decoder, batch_size, with_crop=False):\n",
    "    \"\"\"Benchmark CPU decode throughput for one full epoch.\"\"\"\n",
    "    num_samples = len(cache)\n",
    "    num_batches = (num_samples + batch_size - 1) // batch_size\n",
    "    indices = np.arange(num_samples, dtype=np.int64)\n",
    "    \n",
    "    total_samples = 0\n",
    "    start = time.perf_counter()\n",
    "    \n",
    "    for i in tqdm(range(num_batches), leave=False):\n",
    "        batch_start = i * batch_size\n",
    "        batch_end = min(batch_start + batch_size, num_samples)\n",
    "        batch_indices = indices[batch_start:batch_end]\n",
    "        \n",
    "        # Load raw data\n",
    "        batch_data = cache.load_batch(batch_indices, fields=['image'])\n",
    "        data = batch_data['image']['data']\n",
    "        sizes = batch_data['image']['sizes']\n",
    "        heights = batch_data['image']['heights']\n",
    "        widths = batch_data['image']['widths']\n",
    "        \n",
    "        # Decode\n",
    "        if with_crop:\n",
    "            images = decoder.decode_batch_random_crop(\n",
    "                data, sizes, heights, widths,\n",
    "                target_size=224,\n",
    "                scale=(0.08, 1.0),\n",
    "            )\n",
    "        else:\n",
    "            images = decoder.decode_batch(data, sizes)\n",
    "        \n",
    "        total_samples += len(batch_indices)\n",
    "    \n",
    "    elapsed = time.perf_counter() - start\n",
    "    samples_per_sec = total_samples / elapsed\n",
    "    \n",
    "    return {\n",
    "        'samples_per_sec': samples_per_sec,\n",
    "        'elapsed_sec': elapsed,\n",
    "        'total_samples': total_samples,\n",
    "    }\n",
    "\n",
    "def benchmark_cpu_decode(cache, decoder, batch_size, num_epochs, num_warmup, with_crop=False):\n",
    "    \"\"\"Benchmark CPU decode over multiple epochs.\"\"\"\n",
    "    crop_str = \"+ RRC\" if with_crop else \"(no crop)\"\n",
    "    \n",
    "    # Warmup (show results)\n",
    "    print(f\"  Warmup ({num_warmup} epoch(s)):\")\n",
    "    for i in range(num_warmup):\n",
    "        result = benchmark_cpu_decode_epoch(cache, decoder, batch_size, with_crop)\n",
    "        print(f\"    Warmup {i + 1}: {result['samples_per_sec']:,.0f} samples/sec ({result['elapsed_sec']:.2f}s)\")\n",
    "    \n",
    "    # Timed epochs\n",
    "    results = []\n",
    "    for epoch in range(num_epochs):\n",
    "        result = benchmark_cpu_decode_epoch(cache, decoder, batch_size, with_crop)\n",
    "        results.append(result)\n",
    "        print(f\"  Epoch {epoch + 1}: {result['samples_per_sec']:,.0f} samples/sec ({result['elapsed_sec']:.2f}s)\")\n",
    "    \n",
    "    avg_samples_per_sec = np.mean([r['samples_per_sec'] for r in results])\n",
    "    \n",
    "    return {\n",
    "        'samples_per_sec': avg_samples_per_sec,\n",
    "        'total_samples': results[0]['total_samples'],\n",
    "        'with_crop': with_crop,\n",
    "    }\n",
    "\n",
    "print(\"Benchmarking CPU decode (full epochs)...\\n\")\n",
    "\n",
    "# Simple decode (no crop)\n",
    "print(\"Simple decode (no crop):\")\n",
    "result_decode = benchmark_cpu_decode(cache, cpu_decoder, BATCH_SIZE, NUM_EPOCHS, NUM_WARMUP, with_crop=False)\n",
    "print(f\"  Average: {result_decode['samples_per_sec']:,.0f} samples/sec\\n\")\n",
    "\n",
    "# Decode with RandomResizedCrop\n",
    "print(\"Decode + RandomResizedCrop:\")\n",
    "result_rrc = benchmark_cpu_decode(cache, cpu_decoder, BATCH_SIZE, NUM_EPOCHS, NUM_WARMUP, with_crop=True)\n",
    "print(f\"  Average: {result_rrc['samples_per_sec']:,.0f} samples/sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## 4. Benchmark SlipstreamLoader (Full Pipeline)\n",
    "\n",
    "This benchmarks the complete training pipeline:\n",
    "- Async I/O with prefetching\n",
    "- CPU decode with RandomResizedCrop\n",
    "- ImageNet normalization\n",
    "- Output to GPU tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream import SlipstreamLoader, RandomResizedCrop, Normalize\n",
    "\n",
    "# Create loader with pipelines - this auto-uses the optimized cache we already built\n",
    "loader = SlipstreamLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,  # Disable shuffle for reproducible benchmarks\n",
    "    pipelines={\n",
    "        'image': [\n",
    "            RandomResizedCrop(224, scale=(0.08, 1.0), device='cpu', num_workers=8),\n",
    "            Normalize(),\n",
    "        ],\n",
    "    },\n",
    "    exclude_fields=['path'],  # Skip loading file paths (not needed for training)\n",
    ")\n",
    "print(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_loader_epoch(loader):\n",
    "    \"\"\"Benchmark full pipeline throughput for one epoch.\"\"\"\n",
    "    total_samples = 0\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    \n",
    "    for batch in tqdm(loader, leave=False):\n",
    "        total_samples += batch['image'].shape[0]\n",
    "        # Simulate minimal work (ensure tensor is materialized)\n",
    "        _ = batch['image'].sum()\n",
    "    \n",
    "    elapsed = time.perf_counter() - start\n",
    "    samples_per_sec = total_samples / elapsed\n",
    "    \n",
    "    return {\n",
    "        'samples_per_sec': samples_per_sec,\n",
    "        'elapsed_sec': elapsed,\n",
    "        'total_samples': total_samples,\n",
    "    }\n",
    "\n",
    "def benchmark_loader_epochs(loader, num_epochs, num_warmup, name=\"Loader\"):\n",
    "    \"\"\"Benchmark loader over multiple epochs.\"\"\"\n",
    "    # Warmup (show results)\n",
    "    print(f\"  Warmup ({num_warmup} epoch(s)):\")\n",
    "    for i in range(num_warmup):\n",
    "        result = benchmark_loader_epoch(loader)\n",
    "        print(f\"    Warmup {i + 1}: {result['samples_per_sec']:,.0f} samples/sec ({result['elapsed_sec']:.2f}s)\")\n",
    "    \n",
    "    # Timed epochs\n",
    "    results = []\n",
    "    for epoch in range(num_epochs):\n",
    "        result = benchmark_loader_epoch(loader)\n",
    "        results.append(result)\n",
    "        print(f\"  Epoch {epoch + 1}: {result['samples_per_sec']:,.0f} samples/sec ({result['elapsed_sec']:.2f}s)\")\n",
    "    \n",
    "    avg_samples_per_sec = np.mean([r['samples_per_sec'] for r in results])\n",
    "    \n",
    "    return {\n",
    "        'samples_per_sec': avg_samples_per_sec,\n",
    "        'total_samples': results[0]['total_samples'],\n",
    "    }\n",
    "\n",
    "print(\"Benchmarking SlipstreamLoader (full epochs)...\\n\")\n",
    "\n",
    "print(\"SlipstreamLoader (train mode, RandomResizedCrop):\")\n",
    "result_loader = benchmark_loader_epochs(loader, NUM_EPOCHS, NUM_WARMUP)\n",
    "print(f\"  Average: {result_loader['samples_per_sec']:,.0f} samples/sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream import CenterCrop\n",
    "\n",
    "# Also test validation mode with CenterCrop pipeline\n",
    "val_loader = SlipstreamLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    pipelines={\n",
    "        'image': [\n",
    "            CenterCrop(224, device='cpu', num_workers=8),\n",
    "            Normalize(),\n",
    "        ],\n",
    "    },\n",
    "    exclude_fields=['path'],\n",
    ")\n",
    "\n",
    "print(\"\\nSlipstreamLoader (val mode, CenterCrop):\")\n",
    "result_val = benchmark_loader_epochs(val_loader, NUM_EPOCHS, NUM_WARMUP)\n",
    "print(f\"  Average: {result_val['samples_per_sec']:,.0f} samples/sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## 5. Summary\n",
    "\n",
    "Results from this benchmark run (full epoch iterations):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Compile results\n",
    "results = [\n",
    "    {'Stage': 'StreamingDataLoader (raw)', 'Samples/sec': result_streaming['samples_per_sec']},\n",
    "    {'Stage': 'SlipstreamLoader (raw)', 'Samples/sec': result_slipstream_raw['samples_per_sec']},\n",
    "    {'Stage': 'OptimizedCache direct', 'Samples/sec': result_io['samples_per_sec']},\n",
    "    {'Stage': 'CPU Decode (no crop)', 'Samples/sec': result_decode['samples_per_sec']},\n",
    "    {'Stage': 'CPU Decode + RRC', 'Samples/sec': result_rrc['samples_per_sec']},\n",
    "    {'Stage': 'Full Pipeline (train)', 'Samples/sec': result_loader['samples_per_sec']},\n",
    "    {'Stage': 'Full Pipeline (val)', 'Samples/sec': result_val['samples_per_sec']},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Calculate epoch time for 50k samples (ImageNet val)\n",
    "num_samples = result_io['total_samples']\n",
    "df['Epoch Time (s)'] = num_samples / df['Samples/sec']\n",
    "df['Samples/sec'] = df['Samples/sec'].apply(lambda x: f\"{x:,.0f}\")\n",
    "df['Epoch Time (s)'] = df['Epoch Time (s)'].apply(lambda x: f\"{x:.2f}\")\n",
    "\n",
    "print(f\"Results (averaged over {NUM_EPOCHS} epochs, {num_samples:,} samples each):\\n\")\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# Highlight the key comparison\n",
    "print(f\"\\n--- Key Finding ---\")\n",
    "print(f\"SlipstreamLoader is {speedup:.0f}x faster than StreamingDataLoader for raw I/O\")\n",
    "print(f\"This speedup comes from memory-mapped access with OS page cache after warmup.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "loader.shutdown()\n",
    "val_loader.shutdown()\n",
    "raw_loader.shutdown()\n",
    "cpu_decoder.shutdown()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "**New Pipeline-Based API:**\n",
    "```python\n",
    "from slipstream import SlipstreamLoader, RandomResizedCrop, CenterCrop, Normalize\n",
    "\n",
    "# Training with pipelines\n",
    "loader = SlipstreamLoader(\n",
    "    dataset,\n",
    "    batch_size=256,\n",
    "    pipelines={\n",
    "        'image': [\n",
    "            RandomResizedCrop(224, device='cuda'),\n",
    "            Normalize(),\n",
    "        ],\n",
    "    },\n",
    ")\n",
    "\n",
    "# Raw I/O (no pipelines, for benchmarking)\n",
    "raw_loader = SlipstreamLoader(dataset, batch_size=256)\n",
    "```\n",
    "\n",
    "**Performance Tips:**\n",
    "- First epoch is slower due to cold cache (chunks downloaded from S3)\n",
    "- Subsequent epochs benefit from OS page cache (near-instantaneous I/O)\n",
    "- Use `device='cuda'` in pipelines for GPU acceleration\n",
    "- Set `num_workers` in RandomResizedCrop/CenterCrop for CPU parallelism\n",
    "\n",
    "**Expected Bottlenecks:**\n",
    "- macOS: CPU decode is the bottleneck (~5-7k samples/sec)\n",
    "- Linux + GPU: Decode matches I/O (~10k samples/sec with nvImageCodec)\n",
    "\n",
    "**Comparison to FFCV:**\n",
    "- Raw I/O: SlipstreamLoader is 37% faster (480k vs 350k samples/sec)\n",
    "- GPU Decode + RRC: Equivalent (~10k samples/sec)\n",
    "- Cold start: 20% faster due to parallel chunk downloads\n",
    "\n",
    "**Key Benefits:**\n",
    "- Composable pipelines: Mix and match decode, crop, normalize\n",
    "- No pipelines = raw bytes: Perfect for benchmarking I/O\n",
    "- Same field names as the original dataset\n",
    "- All fields accessible: image, label, index, path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
