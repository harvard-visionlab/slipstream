{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# SlipstreamDataset Basics\n",
    "\n",
    "This notebook demonstrates the basic usage of `SlipstreamDataset` for loading datasets from various sources.\n",
    "\n",
    "## Features\n",
    "\n",
    "- **Auto-detection**: Automatically detects format (LitData streaming, FFCV, ImageFolder)\n",
    "- **Composition pattern**: Wraps pluggable readers (StreamingReader, FFCVFileReader, SlipstreamImageFolder)\n",
    "- **Flexible decoding**: Raw bytes (for training) or decoded images (for exploration)\n",
    "- **Pipeline support**: Per-field transforms via `SlipstreamLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataset paths\n",
    "LITDATA_VAL_PATH = \"s3://visionlab-datasets/imagenet1k/pre-processed/s256-l512-jpgbytes-q100-streaming/val/\"\n",
    "FFCV_VAL_PATH = \"s3://visionlab-datasets/imagenet1k/pre-processed/s256-l512-jpgbytes-q100-ffcv/imagenet1k-s256-l512-jpg-q100-cs100-val-7ac6386e.ffcv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1. Basic Usage: Load and Inspect Dataset\n",
    "\n",
    "Use `decode_images=True` for interactive exploration. The reader type is auto-detected from the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream import SlipstreamDataset\n",
    "\n",
    "# Create dataset with automatic decoding (for exploration)\n",
    "dataset = SlipstreamDataset(\n",
    "    remote_dir=LITDATA_VAL_PATH,\n",
    "    decode_images=True,\n",
    "    to_pil=True,\n",
    ")\n",
    "\n",
    "# Show dataset info\n",
    "print(f\"Reader type: {type(dataset._reader).__name__}\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample\n",
    "sample = dataset[0]\n",
    "print(f\"Sample keys: {list(sample.keys())}\")\n",
    "print(f\"Image type: {type(sample['image'])}\")\n",
    "print(f\"Label: {sample['label']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the image\n",
    "sample['image']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 2. Raw Bytes Mode (for high-performance training)\n",
    "\n",
    "For training, use `decode_images=False` and let `SlipstreamLoader` handle decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset WITHOUT automatic decoding\n",
    "# This is what you'd use with SlipstreamLoader for training\n",
    "dataset_raw = SlipstreamDataset(\n",
    "    remote_dir=LITDATA_VAL_PATH,\n",
    "    decode_images=False,\n",
    ")\n",
    "\n",
    "dataset_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get raw sample\n",
    "sample_raw = dataset_raw[0]\n",
    "print(f\"Image type: {type(sample_raw['image'])}\")\n",
    "print(f\"Image size: {len(sample_raw['image'])} bytes\")\n",
    "print(f\"First 16 bytes (JPEG header): {sample_raw['image'][:16].hex()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual decoding (what the loader will do)\n",
    "from slipstream import decode_image\n",
    "\n",
    "image_tensor = decode_image(sample_raw['image'], to_pil=False)\n",
    "print(f\"Decoded tensor shape: {image_tensor.shape}\")\n",
    "print(f\"Decoded tensor dtype: {image_tensor.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 3. SlipstreamLoader with Pipeline Presets\n",
    "\n",
    "For training, use `SlipstreamLoader` with pipeline presets. This handles:\n",
    "- Building an optimized cache for fast I/O\n",
    "- Batch decoding with random/center crop\n",
    "- GPU transfers and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream import SlipstreamDataset, SlipstreamLoader\n",
    "from slipstream.pipelines import supervised_train, supervised_val\n",
    "\n",
    "# Training loader with random resized crop + augmentations\n",
    "dataset = SlipstreamDataset(remote_dir=LITDATA_VAL_PATH, decode_images=False)\n",
    "\n",
    "train_loader = SlipstreamLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    pipelines=supervised_train(size=224, seed=42, device=\"cpu\"),\n",
    ")\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "print(f\"Batch keys: {list(batch.keys())}\")\n",
    "print(f\"Image shape: {batch['image'].shape}\")  # [B, C, H, W]\n",
    "print(f\"Image dtype: {batch['image'].dtype}\")\n",
    "print(f\"Labels: {batch['label'][:8].tolist()}\")\n",
    "train_loader.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation loader with center crop\n",
    "val_loader = SlipstreamLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    pipelines=supervised_val(size=224, device=\"cpu\"),\n",
    ")\n",
    "\n",
    "batch = next(iter(val_loader))\n",
    "print(f\"Val batch shape: {batch['image'].shape}\")\n",
    "val_loader.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## 4. Custom Pipelines with Decoders\n",
    "\n",
    "For more control, use decoder stages directly. All decoders have a `Decode` prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream import SlipstreamLoader, DecodeCenterCrop, DecodeRandomResizedCrop\n",
    "\n",
    "# Custom pipeline: just decode + crop (no normalization)\n",
    "loader_custom = SlipstreamLoader(\n",
    "    dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    pipelines={'image': [DecodeCenterCrop(224)]},\n",
    "    exclude_fields=['path'],\n",
    ")\n",
    "\n",
    "batch = next(iter(loader_custom))\n",
    "print(f\"Image shape: {batch['image'].shape}\")\n",
    "print(f\"Image dtype: {batch['image'].dtype}\")  # uint8 (no normalization)\n",
    "loader_custom.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add normalization for training\n",
    "from slipstream import Normalize, ToTorchImage\n",
    "from slipstream.transforms import IMAGENET_MEAN, IMAGENET_STD\n",
    "\n",
    "loader_norm = SlipstreamLoader(\n",
    "    dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    pipelines={'image': [\n",
    "        DecodeRandomResizedCrop(224),\n",
    "        ToTorchImage(device='cpu', dtype='float32'),\n",
    "        Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "    ]},\n",
    "    exclude_fields=['path'],\n",
    ")\n",
    "\n",
    "batch = next(iter(loader_norm))\n",
    "print(f\"Image shape: {batch['image'].shape}\")\n",
    "print(f\"Image dtype: {batch['image'].dtype}\")\n",
    "print(f\"Image range: [{batch['image'].min():.3f}, {batch['image'].max():.3f}]\")\n",
    "loader_norm.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## 5. FFCV File Format\n",
    "\n",
    "`SlipstreamDataset` auto-detects `.ffcv`/`.beton` files and uses `FFCVFileReader` internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream import SlipstreamDataset, decode_image\n",
    "\n",
    "# Just pass the FFCV path - auto-detected\n",
    "dataset_ffcv = SlipstreamDataset(FFCV_VAL_PATH)\n",
    "print(f\"Reader type: {type(dataset_ffcv._reader).__name__}\")\n",
    "dataset_ffcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset_ffcv[0]\n",
    "print(f\"Sample keys: {list(sample.keys())}\")\n",
    "print(f\"Label: {sample['label']}\")\n",
    "print(f\"Path: {sample['path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode and display\n",
    "decode_image(sample['image'], to_pil=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use with SlipstreamLoader (builds optimized cache on first use)\n",
    "from slipstream import SlipstreamLoader, DecodeRandomResizedCrop\n",
    "\n",
    "loader_ffcv = SlipstreamLoader(\n",
    "    dataset_ffcv,\n",
    "    batch_size=256,\n",
    "    pipelines={'image': [DecodeRandomResizedCrop(224)]},\n",
    "    exclude_fields=['path'],\n",
    ")\n",
    "\n",
    "loader_ffcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(loader_ffcv))\n",
    "print(f\"Batch keys: {list(batch.keys())}\")\n",
    "print(f\"Image shape: {batch['image'].shape}\")\n",
    "print(f\"Labels: {batch['label'][:5].tolist()}\")\n",
    "loader_ffcv.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**SlipstreamDataset** provides:\n",
    "- **Auto-detection**: Detects LitData, FFCV, or ImageFolder from the path\n",
    "- **Composition pattern**: Wraps readers (StreamingReader, FFCVFileReader, SlipstreamImageFolder)\n",
    "- **Flexible decoding**: `decode_images=True` for exploration, `False` for training\n",
    "\n",
    "**SlipstreamLoader** provides:\n",
    "- **Optimized cache**: Builds a slip cache for fast batch I/O\n",
    "- **Pipeline presets**: `supervised_train()`, `supervised_val()`, `simclr()`, `lejepa()`, etc.\n",
    "- **Custom pipelines**: Combine `DecodeCenterCrop`, `DecodeRandomResizedCrop`, `Normalize`, etc.\n",
    "\n",
    "**Key patterns**:\n",
    "- `decode_images=True` for interactive exploration (PIL/tensor output)\n",
    "- `decode_images=False` + `SlipstreamLoader(pipelines=...)` for training\n",
    "- Decoder stages use `Decode` prefix: `DecodeCenterCrop`, `DecodeRandomResizedCrop`\n",
    "\n",
    "**Next**: See `02_field_indexes.ipynb` for class-based subsetting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
