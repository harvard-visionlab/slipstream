{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HuggingFace Dataset Support\n",
    "\n",
    "This notebook demonstrates how to use HuggingFace datasets with slipstream via the `hf://` URI scheme.\n",
    "\n",
    "## HuggingFace Image Format\n",
    "\n",
    "HuggingFace stores images in Parquet as dicts:\n",
    "```python\n",
    "{'bytes': b'\\x89PNG...', 'path': None}  # inline bytes\n",
    "{'bytes': None, 'path': '/path/to/image.jpg'}  # path reference\n",
    "```\n",
    "\n",
    "Slipstream automatically detects and decodes this format when `decode_images=True`.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "The required dependencies are already included in slipstream:\n",
    "- `huggingface_hub` - HuggingFace Hub client\n",
    "- `hf_transfer` - Fast file transfers (optional, for high-bandwidth networks)\n",
    "\n",
    "To enable faster downloads:\n",
    "```bash\n",
    "export HF_HUB_ENABLE_HF_TRANSFER=1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HUB_ENABLE_HF_TRANSFER'] = '1'\n",
    "\n",
    "from slipstream import SlipstreamDataset, SlipstreamLoader\n",
    "from slipstream.dataset import is_hf_image_dict, is_image_bytes, decode_image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding HuggingFace Image Dicts\n",
    "\n",
    "Let's look at what the raw HuggingFace format looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST without decoding to see the raw HuggingFace format\n",
    "dataset_raw = SlipstreamDataset(\n",
    "    input_dir=\"hf://datasets/ylecun/mnist/mnist/\",\n",
    "    decode_images=False,  # See raw format\n",
    ")\n",
    "\n",
    "sample = dataset_raw[0]\n",
    "print(\"Raw sample keys:\", list(sample.keys()))\n",
    "print(\"Raw 'image' type:\", type(sample['image']))\n",
    "print(\"Raw 'image' value:\", {k: type(v).__name__ for k, v in sample['image'].items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slipstream automatically detects HuggingFace image dicts\n",
    "hf_dict = sample['image']\n",
    "print(f\"Is HF image dict: {is_hf_image_dict(hf_dict)}\")\n",
    "print(f\"Is valid image: {is_image_bytes(hf_dict)}\")\n",
    "print(f\"Detected field types: {dataset_raw.field_types}\")\n",
    "print(f\"Image fields: {dataset_raw.image_fields}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually decode using decode_image()\n",
    "img_tensor = decode_image(hf_dict, to_pil=False)\n",
    "img_pil = decode_image(hf_dict, to_pil=True)\n",
    "\n",
    "print(f\"Tensor shape: {img_tensor.shape} (CHW)\")\n",
    "print(f\"PIL size: {img_pil.size}\")\n",
    "img_pil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Decoding with SlipstreamDataset\n",
    "\n",
    "Set `decode_images=True` to automatically decode HuggingFace image dicts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST with automatic decoding\n",
    "dataset = SlipstreamDataset(\n",
    "    input_dir=\"hf://datasets/ylecun/mnist/mnist/\",\n",
    "    decode_images=True,\n",
    "    to_pil=True,\n",
    ")\n",
    "\n",
    "print(dataset)\n",
    "sample = dataset[0]\n",
    "print(f\"\\nSample 'image' type: {type(sample['image'])}\")\n",
    "sample['image']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10 Example\n",
    "\n",
    "CIFAR-10 uses the field name 'img' instead of 'image' - slipstream handles this automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 - note the field is 'img' not 'image'\n",
    "dataset = SlipstreamDataset(\n",
    "    input_dir=\"hf://datasets/uoft-cs/cifar10/plain_text/\",\n",
    "    decode_images=True,\n",
    "    to_pil=True,\n",
    ")\n",
    "\n",
    "print(dataset)\n",
    "sample = dataset[0]\n",
    "print(f\"\\nField names: {list(sample.keys())}\")\n",
    "sample['img']  # CIFAR-10 uses 'img' field name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some CIFAR-10 samples\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "\n",
    "cifar10_classes = [\n",
    "    'airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "    'dog', 'frog', 'horse', 'ship', 'truck'\n",
    "]\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    sample = dataset[i]\n",
    "    ax.imshow(sample['img'])\n",
    "    ax.set_title(cifar10_classes[sample['label']])\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('CIFAR-10 from HuggingFace (auto-decoded)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Field Name Variability\n",
    "\n",
    "HuggingFace doesn't enforce column names. Common patterns:\n",
    "- Images: `image`, `img`, `pixel_values`\n",
    "- Labels: `label`, `labels`, `fine_label`, `coarse_label`\n",
    "\n",
    "Slipstream detects images by format (not name), so any field containing\n",
    "HuggingFace image dicts will be automatically detected and decoded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other HuggingFace Datasets\n",
    "\n",
    "You can load any LitData-compatible HuggingFace dataset using the `hf://` URI:\n",
    "\n",
    "```python\n",
    "# ImageNet subset\n",
    "dataset = SlipstreamDataset(input_dir=\"hf://datasets/imagenet-1k/data\")\n",
    "\n",
    "# MNIST\n",
    "dataset = SlipstreamDataset(input_dir=\"hf://datasets/ylecun/mnist/mnist/\")\n",
    "\n",
    "# Custom datasets\n",
    "dataset = SlipstreamDataset(input_dir=\"hf://datasets/username/my-dataset/data\")\n",
    "```\n",
    "\n",
    "Note: The dataset must be in a format compatible with LitData's streaming protocol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SlipstreamLoader\n",
    "\n",
    "Automatically convert huggingface dataset to .slip format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream import SlipstreamDataset, SlipstreamLoader, DecodeCenterCrop, DecodeYUVFullRes\n",
    "from PIL import Image\n",
    "\n",
    "dataset = SlipstreamDataset(                                                                                                                                                             \n",
    "    input_dir=\"hf://datasets/uoft-cs/cifar10/plain_text/\",\n",
    "    decode_images=False,                                                                                                                                                               \n",
    ")                                                                                                                                                                                      \n",
    "print(dataset)\n",
    "\n",
    "loader = SlipstreamLoader(                                                                                                                                                             \n",
    "    dataset,                                                                                                                                                                           \n",
    "    batch_size=100,     \n",
    "    pipelines={'img': [DecodeCenterCrop(size=32)]},                                                                                                                                       \n",
    "    force_rebuild=True,  # Rebuild cache with correct format                                                                                                                                  \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = SlipstreamDataset(                                                                                                                                                             \n",
    "#     input_dir=\"hf://datasets/uoft-cs/cifar10/plain_text/\",\n",
    "#     decode_images=False,\n",
    "# ) \n",
    "# dataset[0]['img']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(loader))\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['img'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch['label'][0])\n",
    "Image.fromarray(batch['img'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream import SlipstreamDataset, SlipstreamLoader, DecodeCenterCrop                                                                                                           \n",
    "from PIL import Image\n",
    "\n",
    "dataset = SlipstreamDataset(                                                                                                                                                           \n",
    "  input_dir=\"hf://datasets/ylecun/mnist/mnist/\",    \n",
    "  # input_dir=\"hf://datasets/uoft-cs/cifar10/plain_text/\",\n",
    "  decode_images=False,                                                                                                                                                               \n",
    ")                                                                                                                                                                                      \n",
    "print(dataset)\n",
    "\n",
    "loader = SlipstreamLoader(                                                                                                                                                             \n",
    "    dataset,                                                                                                                                                                           \n",
    "    batch_size=100,     \n",
    "    pipelines={'image': [DecodeCenterCrop(28)]},                                                                                                                                       \n",
    "    force_rebuild=True,  # Rebuild cache with correct format                                                                                                                                  \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(loader))\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['image'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(batch['image'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
