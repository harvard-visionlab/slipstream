{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# FFCV Dataset Support\n",
    "\n",
    "This notebook demonstrates slipstream's support for FFCV `.beton`/`.ffcv` files.\n",
    "\n",
    "**Supported formats:**\n",
    "- Local `.ffcv` / `.beton` files\n",
    "- Remote S3 paths (auto-download with s5cmd or fsspec)\n",
    "- Automatic format detection via `SlipstreamDataset`\n",
    "\n",
    "**What's happening under the hood:**\n",
    "- `FFCVFileReader` reads the binary FFCV format directly (no FFCV dependency needed)\n",
    "- Image bytes, labels, and metadata are extracted from the memory-mapped file\n",
    "- `SlipstreamLoader` builds an optimized cache for fast iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1. Dataset Creation via SlipstreamDataset\n",
    "\n",
    "`SlipstreamDataset` auto-detects `.ffcv`/`.beton` files from any argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream import SlipstreamDataset\n",
    "\n",
    "FFCV_VAL_PATH = \"s3://visionlab-datasets/imagenet1k/pre-processed/s256-l512-jpgbytes-q100-ffcv/imagenet1k-s256-l512-jpg-q100-cs100-val-7ac6386e.ffcv\"\n",
    "\n",
    "# Just pass the path — auto-detected as FFCV\n",
    "dataset = SlipstreamDataset(FFCV_VAL_PATH)\n",
    "\n",
    "print(f\"Dataset type: {type(dataset).__name__}\")\n",
    "print(f\"Reader type: {type(dataset._reader).__name__}\")\n",
    "print(f\"Number of samples: {len(dataset):,}\")\n",
    "print(f\"Field types: {dataset.field_types}\")\n",
    "print(f\"Image fields: {dataset.image_fields}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repr shows FFCV-specific info\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## 2. Inspect Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream import decode_image\n",
    "\n",
    "sample = dataset[0]\n",
    "print(f\"Sample keys: {list(sample.keys())}\")\n",
    "print(f\"Label: {sample['label']}\")\n",
    "print(f\"Image bytes (first 20): {sample['image'][:20]}...\")\n",
    "print(f\"Image size: {len(sample['image']):,} bytes\")\n",
    "print(f\"Path: {sample['path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode and display\n",
    "img = decode_image(sample['image'], to_pil=True)\n",
    "print(f\"Decoded size: {img.size}\")\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or use decode_images=True for automatic decoding\n",
    "dataset_decoded = SlipstreamDataset(FFCV_VAL_PATH, decode_images=True)\n",
    "sample = dataset_decoded[0]\n",
    "print(f\"Image type: {type(sample['image']).__name__}\")\n",
    "sample['image']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## 3. Alternative Creation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of these are equivalent:\n",
    "dataset1 = SlipstreamDataset(FFCV_VAL_PATH)                    # positional (remote_dir)\n",
    "dataset2 = SlipstreamDataset(remote_dir=FFCV_VAL_PATH)         # explicit remote_dir\n",
    "dataset3 = SlipstreamDataset(input_dir=FFCV_VAL_PATH)          # input_dir also works\n",
    "\n",
    "print(f\"All have same length: {len(dataset1) == len(dataset2) == len(dataset3)}\")\n",
    "print(f\"All use FFCVFileReader: {all(type(d._reader).__name__ == 'FFCVFileReader' for d in [dataset1, dataset2, dataset3])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream.readers import FFCVFileReader\n",
    "\n",
    "# Or create the reader directly (power user)\n",
    "reader = FFCVFileReader(FFCV_VAL_PATH)\n",
    "print(reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 4. SlipstreamLoader with Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream import SlipstreamLoader, DecodeCenterCrop, ToTorchImage\n",
    "\n",
    "dataset = SlipstreamDataset(FFCV_VAL_PATH)\n",
    "\n",
    "loader = SlipstreamLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    pipelines={\n",
    "        \"image\": [\n",
    "            DecodeCenterCrop(size=224),\n",
    "        ]\n",
    "    },\n",
    "    force_rebuild=True,\n",
    ")\n",
    "\n",
    "batch = next(iter(loader))\n",
    "print(f\"Batch keys: {list(batch.keys())}\")\n",
    "print(f\"Image shape: {batch['image'].shape}\")\n",
    "print(f\"Image dtype: {batch['image'].dtype}\")\n",
    "print(f\"Labels: {batch['label'][:8].tolist()}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Using Pipeline Presets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream import SlipstreamDataset, SlipstreamLoader, DecodeCenterCrop, ToTorchImage\n",
    "from slipstream.pipelines import supervised_train, supervised_val\n",
    "\n",
    "FFCV_VAL_PATH = \"s3://visionlab-datasets/imagenet1k/pre-processed/s256-l512-jpgbytes-q100-ffcv/imagenet1k-s256-l512-jpg-q100-cs100-val-7ac6386e.ffcv\"\n",
    "\n",
    "# Just pass the path — auto-detected as FFCV\n",
    "dataset = SlipstreamDataset(FFCV_VAL_PATH)\n",
    "# Validation preset\n",
    "val_loader = SlipstreamLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    pipelines=supervised_val(size=224, device=\"cpu\"),\n",
    "    # exclude_fields=['path']\n",
    ")\n",
    "batch = next(iter(val_loader))\n",
    "print(f\"Val batch: {batch['image'].shape}, dtype={batch['image'].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream import SlipstreamLoader, DecodeCenterCrop, ToTorchImage\n",
    "\n",
    "# Training preset\n",
    "train_loader = SlipstreamLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    pipelines=supervised_train(size=224, seed=42, device=\"cpu\"),\n",
    "    # exclude_fields=['path']\n",
    ")\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "print(f\"Train batch: {batch['image'].shape}, dtype={batch['image'].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## 5. Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    sample = dataset[i * 100]\n",
    "    img = decode_image(sample['image'], to_pil=True)\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(f\"label={sample['label']}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle(\"FFCV Dataset Samples\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Dataset Creation:**\n",
    "```python\n",
    "# Auto-detection (recommended)\n",
    "dataset = SlipstreamDataset(\"s3://bucket/data.ffcv\")\n",
    "dataset = SlipstreamDataset(local_dir=\"/path/to/data.beton\")\n",
    "\n",
    "# Explicit\n",
    "reader = FFCVFileReader(\"/path/to/data.ffcv\")\n",
    "```\n",
    "\n",
    "**DataLoader Creation:**\n",
    "```python\n",
    "# High-performance training\n",
    "loader = SlipstreamLoader(\n",
    "    dataset,\n",
    "    batch_size=256,\n",
    "    pipelines=supervised_train(224, device=\"cuda\"),\n",
    ")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
