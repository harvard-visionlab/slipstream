{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Transform Visual Verification\n",
    "\n",
    "Visual comparison of slipstream GPU batch transforms vs torchvision v2 equivalents.\n",
    "\n",
    "1. **Deterministic transforms** — exact match expected (difference heatmap)\n",
    "2. **Geometric transforms** — qualitative side-by-side (different RNG)\n",
    "3. **Color transforms** — qualitative side-by-side\n",
    "4. **Effect transforms** — qualitative side-by-side\n",
    "5. **Slipstream-only transforms** — before/after\n",
    "6. **SSL replay demo** — `apply_last` replays identical params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Section 0: Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(images, title=\"\", nrow=8, figsize=None):\n",
    "    \"\"\"Display a grid of images from a [B, C, H, W] float32 [0,1] tensor.\"\"\"\n",
    "    if isinstance(images, torch.Tensor):\n",
    "        images = images.detach().cpu().clamp(0, 1)\n",
    "    n = min(len(images), nrow * 2)\n",
    "    ncols = min(n, nrow)\n",
    "    nrows = (n + ncols - 1) // ncols\n",
    "    if figsize is None:\n",
    "        figsize = (ncols * 1.8, nrows * 1.8)\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "    if nrows == 1 and ncols == 1:\n",
    "        axes = [[axes]]\n",
    "    elif nrows == 1:\n",
    "        axes = [list(axes)]\n",
    "    elif ncols == 1:\n",
    "        axes = [[ax] for ax in axes]\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            idx = i * ncols + j\n",
    "            ax = axes[i][j]\n",
    "            if idx < n:\n",
    "                img = images[idx].permute(1, 2, 0).numpy()\n",
    "                ax.imshow(img)\n",
    "            ax.axis('off')\n",
    "    if title:\n",
    "        fig.suptitle(title, fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_comparison(original, ss_out, tv_out, title, nrow=4):\n",
    "    \"\"\"3-panel: Original | Slipstream | Torchvision.\"\"\"\n",
    "    original = original.detach().cpu().clamp(0, 1)\n",
    "    ss_out = ss_out.detach().cpu().clamp(0, 1)\n",
    "    tv_out = tv_out.detach().cpu().clamp(0, 1)\n",
    "    n = min(len(original), nrow)\n",
    "    fig, axes = plt.subplots(3, n, figsize=(n * 2, 6.5))\n",
    "    for i in range(n):\n",
    "        axes[0][i].imshow(original[i].permute(1, 2, 0).numpy())\n",
    "        axes[0][i].axis('off')\n",
    "        axes[1][i].imshow(ss_out[i].permute(1, 2, 0).numpy())\n",
    "        axes[1][i].axis('off')\n",
    "        axes[2][i].imshow(tv_out[i].permute(1, 2, 0).numpy())\n",
    "        axes[2][i].axis('off')\n",
    "    axes[0][0].set_ylabel('Original', fontsize=11)\n",
    "    axes[1][0].set_ylabel('Slipstream', fontsize=11)\n",
    "    axes[2][0].set_ylabel('Torchvision', fontsize=11)\n",
    "    fig.suptitle(title, fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_comparison_with_diff(original, ss_out, tv_out, title, nrow=4):\n",
    "    \"\"\"4-panel: Original | Slipstream | Torchvision | Difference heatmap.\n",
    "\n",
    "    Diff heatmap uses fixed vmax=1.0 so only meaningful differences are visible.\n",
    "    \"\"\"\n",
    "    original = original.detach().cpu().clamp(0, 1)\n",
    "    ss_out = ss_out.detach().cpu().float()\n",
    "    tv_out = tv_out.detach().cpu().float()\n",
    "    diff = (ss_out - tv_out).abs()\n",
    "    n = min(len(original), nrow)\n",
    "    fig, axes = plt.subplots(4, n, figsize=(n * 2, 8.5))\n",
    "    for i in range(n):\n",
    "        axes[0][i].imshow(original[i].clamp(0, 1).permute(1, 2, 0).numpy())\n",
    "        axes[0][i].axis('off')\n",
    "        axes[1][i].imshow(ss_out[i].clamp(0, 1).permute(1, 2, 0).numpy())\n",
    "        axes[1][i].axis('off')\n",
    "        axes[2][i].imshow(tv_out[i].clamp(0, 1).permute(1, 2, 0).numpy())\n",
    "        axes[2][i].axis('off')\n",
    "        # Mean diff across channels, fixed scale [0, 1] so zero diff = black\n",
    "        d = diff[i].mean(0).numpy()\n",
    "        im = axes[3][i].imshow(d, cmap='hot', vmin=0, vmax=1.0)\n",
    "        axes[3][i].axis('off')\n",
    "    axes[0][0].set_ylabel('Original', fontsize=11)\n",
    "    axes[1][0].set_ylabel('Slipstream', fontsize=11)\n",
    "    axes[2][0].set_ylabel('Torchvision', fontsize=11)\n",
    "    axes[3][0].set_ylabel('|Diff|', fontsize=11)\n",
    "    max_diff = diff.max().item()\n",
    "    mean_diff = diff.mean().item()\n",
    "    fig.suptitle(f\"{title}\\nmax |diff|={max_diff:.6f}, mean |diff|={mean_diff:.6f}\", fontsize=13, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_before_after(original, transformed, title, nrow=4):\n",
    "    \"\"\"2-panel: Original | Transformed.\"\"\"\n",
    "    original = original.detach().cpu().clamp(0, 1)\n",
    "    # transformed may have != 3 channels, handle gracefully\n",
    "    transformed = transformed.detach().cpu()\n",
    "    n = min(len(original), nrow)\n",
    "    fig, axes = plt.subplots(2, n, figsize=(n * 2, 4.5))\n",
    "    for i in range(n):\n",
    "        axes[0][i].imshow(original[i].permute(1, 2, 0).numpy())\n",
    "        axes[0][i].axis('off')\n",
    "        t = transformed[i]\n",
    "        if t.shape[0] == 3:\n",
    "            axes[1][i].imshow(t.clamp(0, 1).permute(1, 2, 0).numpy())\n",
    "        elif t.shape[0] == 1:\n",
    "            axes[1][i].imshow(t[0].numpy(), cmap='gray')\n",
    "        else:\n",
    "            # Show first 3 channels or grayscale of first channel\n",
    "            axes[1][i].imshow(t[0].numpy(), cmap='viridis')\n",
    "        axes[1][i].axis('off')\n",
    "    axes[0][0].set_ylabel('Original', fontsize=11)\n",
    "    axes[1][0].set_ylabel('Transformed', fontsize=11)\n",
    "    fig.suptitle(title, fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def load_test_batch(n=8):\n",
    "    \"\"\"Load real images from ImageNet val via SlipstreamLoader, return [B,C,H,W] float32 [0,1].\"\"\"\n",
    "    from slipstream import SlipstreamDataset, SlipstreamLoader, CenterCrop\n",
    "    LITDATA_VAL_PATH = \"s3://visionlab-datasets/imagenet1k/pre-processed/s256-l512-jpgbytes-q100-streaming/val/\"\n",
    "    dataset = SlipstreamDataset(remote_dir=LITDATA_VAL_PATH, decode_images=False)\n",
    "    loader = SlipstreamLoader(\n",
    "        dataset, batch_size=n, shuffle=False,\n",
    "        pipelines={'image': [CenterCrop(224)]},\n",
    "        exclude_fields=['path'], verbose=False,\n",
    "    )\n",
    "    batch = next(iter(loader))\n",
    "    loader.shutdown()\n",
    "    # Convert uint8 [0,255] -> float32 [0,1]\n",
    "    images = batch['image'].float() / 255.0\n",
    "    return images\n",
    "\n",
    "print(\"Helpers defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test images (or use synthetic if no dataset available)\n",
    "try:\n",
    "    images = load_test_batch(n=8)\n",
    "    print(f\"Loaded real images: {images.shape}, dtype={images.dtype}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not load real images ({e}), using synthetic data\")\n",
    "    images = torch.rand(8, 3, 224, 224, dtype=torch.float32)\n",
    "\n",
    "images = images.to(DEVICE)\n",
    "show_batch(images, title=\"Test Images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Section 1: Deterministic Transforms (exact match expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream.transforms import Normalize\n",
    "\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "ss_norm = Normalize(MEAN, STD, device=DEVICE)\n",
    "tv_norm = v2.Normalize(MEAN, STD)\n",
    "\n",
    "ss_out = ss_norm(images.clone())\n",
    "# TV per-sample\n",
    "tv_out = torch.stack([tv_norm(images[i].cpu()) for i in range(len(images))]).to(DEVICE)\n",
    "\n",
    "show_comparison_with_diff(images, ss_out, tv_out, \"Normalize vs v2.Normalize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream.transforms import ToGrayscale\n",
    "\n",
    "ss_gray = ToGrayscale(num_output_channels=3)\n",
    "tv_gray = v2.Grayscale(3)\n",
    "\n",
    "ss_out = ss_gray(images.clone())\n",
    "tv_out = torch.stack([tv_gray(images[i].cpu()) for i in range(len(images))]).to(DEVICE)\n",
    "\n",
    "show_comparison_with_diff(images, ss_out, tv_out, \"ToGrayscale vs v2.Grayscale(3)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Section 2: Geometric Transforms (fixed-parameter comparison)\n",
    "\n",
    "Force identical parameters in both SS and TV to enable exact comparison with difference heatmaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream.transforms import RandomHorizontalFlip\n",
    "\n",
    "# p=1.0 is deterministic — all images flipped\n",
    "ss_flip = RandomHorizontalFlip(p=1.0, device=DEVICE)\n",
    "tv_flip = v2.RandomHorizontalFlip(p=1.0)\n",
    "\n",
    "ss_out = ss_flip(images.clone())\n",
    "tv_out = torch.stack([tv_flip(images[i].cpu()) for i in range(len(images))]).to(DEVICE)\n",
    "\n",
    "show_comparison_with_diff(images, ss_out, tv_out, \"RandomHorizontalFlip (p=1.0, deterministic)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2.RandomRotation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream.transforms import RandomRotate\n",
    "from torchvision.transforms import functional as TF\n",
    "\n",
    "B = len(images)\n",
    "\n",
    "# Test two fixed angles: 15° and 30°\n",
    "for angle in [15.0, 30.0]:\n",
    "    ss_rot = RandomRotate(p=1.0, max_deg=angle, device=DEVICE)\n",
    "    deg = torch.full((B,), angle, device=DEVICE)\n",
    "    ss_out = ss_rot(images.clone(), deg=deg)\n",
    "    tv_out = torch.stack([TF.rotate(images[i].cpu(), angle) for i in range(B)]).to(DEVICE)\n",
    "\n",
    "    show_comparison_with_diff(images, ss_out, tv_out, f\"RandomRotate — fixed {angle}°\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream.transforms import RandomZoom\n",
    "\n",
    "B = len(images)\n",
    "\n",
    "# SS zoom=0.5 means \"zoom in 2x\" (magnify), TV scale=0.5 means \"shrink to half\".\n",
    "# So TV scale = 1/zoom to match SS behavior.\n",
    "for zoom_val in [0.5, 0.75]:\n",
    "    ss_zoom = RandomZoom(p=1.0, zoom=(zoom_val, zoom_val), device=DEVICE)\n",
    "    zoom_t = torch.full((B,), zoom_val, device=DEVICE)\n",
    "    ss_out = ss_zoom(images.clone(), zoom=zoom_t)\n",
    "    tv_scale = 1.0 / zoom_val  # invert: SS zoom=0.5 → TV scale=2.0\n",
    "    tv_out = torch.stack([\n",
    "        TF.affine(images[i].cpu(), angle=0, translate=[0, 0], scale=tv_scale, shear=0)\n",
    "        for i in range(B)\n",
    "    ]).to(DEVICE)\n",
    "\n",
    "    show_comparison_with_diff(images, ss_out, tv_out, f\"RandomZoom(zoom={zoom_val}) vs TF.affine(scale={tv_scale:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Section 3: Color Transforms\n",
    "\n",
    "Deterministic where possible (fixed params); qualitative where algorithms differ (YIQ vs RGB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream.transforms import RandomGrayscale\n",
    "\n",
    "# p=1.0: all images converted to grayscale (deterministic)\n",
    "ss_rg = RandomGrayscale(p=1.0, num_output_channels=3, device=DEVICE)\n",
    "tv_rg = v2.Grayscale(3)  # Use deterministic Grayscale, not RandomGrayscale\n",
    "\n",
    "ss_out = ss_rg(images.clone())\n",
    "tv_out = torch.stack([tv_rg(images[i].cpu()) for i in range(len(images))]).to(DEVICE)\n",
    "\n",
    "show_comparison_with_diff(images, ss_out, tv_out, \"RandomGrayscale(p=1.0) vs v2.Grayscale(3) — should match\")\n",
    "\n",
    "# Also show p=0.5 batch to demonstrate per-image randomization\n",
    "ss_rg_rand = RandomGrayscale(p=0.5, num_output_channels=3, device=DEVICE)\n",
    "images16 = images[:4].repeat(4, 1, 1, 1)\n",
    "ss_out_rand = ss_rg_rand(images16.clone())\n",
    "show_batch(ss_out_rand, title=\"RandomGrayscale(p=0.5) — per-image randomization demo\", nrow=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream.transforms import RandomBrightness\n",
    "\n",
    "B = len(images)\n",
    "\n",
    "# Fixed brightness factors\n",
    "for factor in [0.6, 1.4]:\n",
    "    ss_br = RandomBrightness(p=1.0, scale_range=(factor, factor), device=DEVICE)\n",
    "    ss_out = ss_br(images.clone())\n",
    "    tv_out = torch.stack([TF.adjust_brightness(images[i].cpu(), factor) for i in range(B)]).to(DEVICE)\n",
    "\n",
    "    show_comparison_with_diff(images, ss_out, tv_out, f\"RandomBrightness — fixed factor={factor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream.transforms import RandomContrast\n",
    "\n",
    "B = len(images)\n",
    "\n",
    "# Fixed contrast factors\n",
    "for factor in [0.6, 1.4]:\n",
    "    ss_ct = RandomContrast(p=1.0, scale_range=(factor, factor), device=DEVICE)\n",
    "    ss_out = ss_ct(images.clone())\n",
    "    tv_out = torch.stack([TF.adjust_contrast(images[i].cpu(), factor) for i in range(B)]).to(DEVICE)\n",
    "\n",
    "    show_comparison_with_diff(images, ss_out, tv_out, f\"RandomContrast — fixed factor={factor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream.transforms import ColorJitter as SSColorJitter\n",
    "\n",
    "B = len(images)\n",
    "\n",
    "# HSV ColorJitter — should match torchvision's ColorJitter\n",
    "# SS params: hue, saturation, value (=brightness), contrast\n",
    "# TV params: brightness, contrast, saturation, hue\n",
    "\n",
    "# Test individual components with fixed values to isolate differences\n",
    "# Use per-image jitter (RandomColorJitter) with fixed params via kwargs\n",
    "\n",
    "# 1. Hue only — fixed value\n",
    "from slipstream.transforms import RandomColorJitter as SSRandomColorJitter\n",
    "\n",
    "for hue_val in [0.1, -0.2]:\n",
    "    ss_jit = SSColorJitter(p=1.0, hue=0.5, device=DEVICE)\n",
    "    h = torch.full((B,), hue_val, device=DEVICE)\n",
    "    ss_out = ss_jit(images.clone(), h=h)\n",
    "    tv_out = torch.stack([TF.adjust_hue(images[i].cpu(), hue_val) for i in range(B)]).to(DEVICE)\n",
    "    show_comparison_with_diff(images, ss_out, tv_out, f\"HSV ColorJitter — hue only, fixed h={hue_val}\")\n",
    "\n",
    "# 2. Saturation only — fixed value\n",
    "for sat_val in [0.5, 1.5]:\n",
    "    ss_jit = SSColorJitter(p=1.0, saturation=2.0, device=DEVICE)\n",
    "    s = torch.full((B,), sat_val, device=DEVICE)\n",
    "    ss_out = ss_jit(images.clone(), s=s)\n",
    "    tv_out = torch.stack([TF.adjust_saturation(images[i].cpu(), sat_val) for i in range(B)]).to(DEVICE)\n",
    "    show_comparison_with_diff(images, ss_out, tv_out, f\"HSV ColorJitter — saturation only, fixed s={sat_val}\")\n",
    "\n",
    "# 3. Value/Brightness only — fixed value\n",
    "for val_val in [0.7, 1.3]:\n",
    "    ss_jit = SSColorJitter(p=1.0, value=2.0, device=DEVICE)\n",
    "    v = torch.full((B,), val_val, device=DEVICE)\n",
    "    ss_out = ss_jit(images.clone(), v=v)\n",
    "    tv_out = torch.stack([TF.adjust_brightness(images[i].cpu(), val_val) for i in range(B)]).to(DEVICE)\n",
    "    show_comparison_with_diff(images, ss_out, tv_out, f\"HSV ColorJitter — value(brightness) only, fixed v={val_val}\")\n",
    "\n",
    "# 4. Contrast only — fixed value\n",
    "for con_val in [0.6, 1.4]:\n",
    "    ss_jit = SSColorJitter(p=1.0, contrast=2.0, device=DEVICE)\n",
    "    c = torch.full((B,), con_val, device=DEVICE)\n",
    "    ss_out = ss_jit(images.clone(), c=c)\n",
    "    tv_out = torch.stack([TF.adjust_contrast(images[i].cpu(), con_val) for i in range(B)]).to(DEVICE)\n",
    "    show_comparison_with_diff(images, ss_out, tv_out, f\"HSV ColorJitter — contrast only, fixed c={con_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream.transforms import RandomColorJitterYIQ\n",
    "\n",
    "# YIQ jitter — flagged for review, qualitative comparison only\n",
    "# TODO: review YIQ jitter algorithm for correctness\n",
    "ss_jit = RandomColorJitterYIQ(p=1.0, hue=20, saturation=0.3, value=0.3, brightness=0.3, contrast=0.3, device=DEVICE)\n",
    "tv_jit = v2.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=20/360)\n",
    "\n",
    "ss_out = ss_jit(images.clone())\n",
    "tv_out = torch.stack([tv_jit(images[i].cpu()) for i in range(len(images))]).to(DEVICE)\n",
    "\n",
    "show_comparison(images, ss_out, tv_out, \"RandomColorJitterYIQ vs v2.ColorJitter — YIQ vs RGB (qualitative, YIQ flagged for review)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Section 4: Effect Transforms (fixed-parameter comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream.transforms import RandomGaussianBlur\n",
    "\n",
    "B = len(images)\n",
    "\n",
    "# Fixed sigma — use p=1.0 and a single sigma value via num_sigmas=1\n",
    "for sigma in [0.5, 2.0]:\n",
    "    ss_blur = RandomGaussianBlur(p=1.0, kernel_size=7, sigma_range=(sigma, sigma), num_sigmas=1, device=DEVICE)\n",
    "    ss_out = ss_blur(images.clone())\n",
    "    tv_out = torch.stack([TF.gaussian_blur(images[i].cpu(), kernel_size=7, sigma=sigma) for i in range(B)]).to(DEVICE)\n",
    "\n",
    "    show_comparison_with_diff(images, ss_out, tv_out, f\"GaussianBlur — fixed sigma={sigma}, kernel=7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream.transforms import RandomSolarization\n",
    "\n",
    "B = len(images)\n",
    "\n",
    "# p=1.0 with fixed threshold — deterministic\n",
    "for threshold in [0.3, 0.5, 0.7]:\n",
    "    ss_sol = RandomSolarization(p=1.0, threshold=threshold, device=DEVICE)\n",
    "    ss_out = ss_sol(images.clone())\n",
    "    tv_out = torch.stack([TF.solarize(images[i].cpu(), threshold) for i in range(B)]).to(DEVICE)\n",
    "\n",
    "    show_comparison_with_diff(images, ss_out, tv_out, f\"Solarization — fixed threshold={threshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Section 5: Slipstream-Only Transforms (before/after)\n",
    "\n",
    "No torchvision equivalent — showing Original → Transformed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream.transforms import RandomPatchShuffle\n",
    "\n",
    "ss_ps = RandomPatchShuffle(sizes=0.25, p=1.0, img_size=224, device=DEVICE)\n",
    "ss_out = ss_ps(images.clone())\n",
    "\n",
    "show_before_after(images, ss_out, \"RandomPatchShuffle(sizes=0.25)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CircularMask?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream.transforms import CircularMask\n",
    "\n",
    "ss_cm = CircularMask(output_size=224, blur_span=8.0, device=DEVICE)\n",
    "ss_out = ss_cm(images.clone())\n",
    "\n",
    "show_before_after(images, ss_out, \"CircularMask(224)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream.transforms import FixedOpticalDistortion\n",
    "\n",
    "ss_barrel = FixedOpticalDistortion(output_size=(224, 224), distortion=-0.5, device=DEVICE)\n",
    "ss_pincushion = FixedOpticalDistortion(output_size=(224, 224), distortion=0.5, device=DEVICE)\n",
    "\n",
    "barrel_out = ss_barrel(images.clone())\n",
    "pincushion_out = ss_pincushion(images.clone())\n",
    "\n",
    "show_before_after(images, barrel_out, \"FixedOpticalDistortion(distortion=-0.5, barrel)\")\n",
    "show_before_after(images, pincushion_out, \"FixedOpticalDistortion(distortion=+0.5, pincushion)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream.transforms import RandomRotate, CircularMask, FixedOpticalDistortion, Compose\n",
    "\n",
    "# Pipeline trick: rotate + circular mask + barrel distortion\n",
    "# The barrel distortion effectively pads the corners, and the circular mask\n",
    "# hides the black borders from rotation. Result: rotation without visible artifacts.\n",
    "resolution = 224\n",
    "\n",
    "pipeline = Compose([\n",
    "    RandomRotate(p=1.0, max_deg=30, x=0.5, y=0.5, device=DEVICE),\n",
    "    # CircularMask(resolution, blur_span=6, device=DEVICE),\n",
    "    FixedOpticalDistortion(resolution, distortion=-.5, device=DEVICE),\n",
    "])\n",
    "\n",
    "# Show multiple runs to see different rotation angles\n",
    "n_runs = 4\n",
    "all_outs = []\n",
    "for _ in range(n_runs):\n",
    "    out = pipeline(images[:4].clone())\n",
    "    all_outs.append(out)\n",
    "\n",
    "# Display: original row, then each pipeline output\n",
    "n = min(4, len(images))\n",
    "fig, axes = plt.subplots(1 + n_runs, n, figsize=(n * 2.2, (1 + n_runs) * 2.2))\n",
    "for i in range(n):\n",
    "    axes[0][i].imshow(images[i].detach().cpu().clamp(0, 1).permute(1, 2, 0).numpy())\n",
    "    axes[0][i].axis('off')\n",
    "axes[0][0].set_ylabel('Original', fontsize=10)\n",
    "\n",
    "for run_idx, out in enumerate(all_outs):\n",
    "    for i in range(n):\n",
    "        axes[run_idx + 1][i].imshow(out[i].detach().cpu().clamp(0, 1).permute(1, 2, 0).numpy())\n",
    "        axes[run_idx + 1][i].axis('off')\n",
    "    axes[run_idx + 1][0].set_ylabel(f'Run {run_idx + 1}', fontsize=10)\n",
    "\n",
    "fig.suptitle(\n",
    "    'Rotate + CircularMask + BarrelDistortion pipeline\\n'\n",
    "    'Random rotation without visible black border artifacts',\n",
    "    fontsize=13, fontweight='bold',\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream.transforms import RandomRotateObject\n",
    "\n",
    "ss_ro = RandomRotateObject(p=1.0, max_deg=30, scale=(1.0, 1.5), device=DEVICE)\n",
    "ss_out = ss_ro(images.clone())\n",
    "\n",
    "show_before_after(images, ss_out, \"RandomRotateObject(30°, scale=1.0-1.5)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream.transforms import SRGBToLMS\n",
    "\n",
    "ss_lms = SRGBToLMS()\n",
    "lms_out = ss_lms(images.clone())\n",
    "\n",
    "# Show individual L, M, S channels\n",
    "n = min(4, len(images))\n",
    "fig, axes = plt.subplots(4, n, figsize=(n * 2, 8.5))\n",
    "lms_cpu = lms_out.detach().cpu()\n",
    "for i in range(n):\n",
    "    axes[0][i].imshow(images[i].detach().cpu().clamp(0,1).permute(1, 2, 0).numpy())\n",
    "    axes[0][i].axis('off')\n",
    "    for ch, label in enumerate(['L', 'M', 'S']):\n",
    "        axes[ch+1][i].imshow(lms_cpu[i, ch].numpy(), cmap='gray')\n",
    "        axes[ch+1][i].axis('off')\n",
    "        if i == 0:\n",
    "            axes[ch+1][i].set_ylabel(label, fontsize=12)\n",
    "axes[0][0].set_ylabel('RGB', fontsize=12)\n",
    "fig.suptitle('SRGBToLMS — L, M, S channels', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream.transforms import RGBToLGN\n",
    "\n",
    "ss_lgn = RGBToLGN(device=DEVICE)\n",
    "lgn_out = ss_lgn(images.clone())\n",
    "print(f\"RGBToLGN output: {lgn_out.shape}\")  # [B, 5, H, W]\n",
    "\n",
    "# Show 5 channels for first 4 images\n",
    "n = min(4, len(images))\n",
    "channel_names = ['Parvo L-M', 'Parvo M-L', 'Magno ON', 'Magno OFF', 'Konio S-(L+M)']\n",
    "lgn_cpu = lgn_out.detach().cpu()\n",
    "fig, axes = plt.subplots(6, n, figsize=(n * 2, 13))\n",
    "for i in range(n):\n",
    "    axes[0][i].imshow(images[i].detach().cpu().clamp(0,1).permute(1, 2, 0).numpy())\n",
    "    axes[0][i].axis('off')\n",
    "    for ch in range(5):\n",
    "        axes[ch+1][i].imshow(lgn_cpu[i, ch].numpy(), cmap='gray')\n",
    "        axes[ch+1][i].axis('off')\n",
    "        if i == 0:\n",
    "            axes[ch+1][i].set_ylabel(channel_names[ch], fontsize=9)\n",
    "axes[0][0].set_ylabel('RGB', fontsize=10)\n",
    "fig.suptitle('RGBToLGN — 5-channel output', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream.transforms import RGBToMagno\n",
    "\n",
    "ss_magno = RGBToMagno(device=DEVICE)\n",
    "magno_out = ss_magno(images.clone())\n",
    "print(f\"RGBToMagno output: {magno_out.shape}\")  # [B, 2, H, W]\n",
    "\n",
    "n = min(4, len(images))\n",
    "magno_cpu = magno_out.detach().cpu()\n",
    "fig, axes = plt.subplots(3, n, figsize=(n * 2, 6.5))\n",
    "for i in range(n):\n",
    "    axes[0][i].imshow(images[i].detach().cpu().clamp(0,1).permute(1, 2, 0).numpy())\n",
    "    axes[0][i].axis('off')\n",
    "    axes[1][i].imshow(magno_cpu[i, 0].numpy(), cmap='gray')\n",
    "    axes[1][i].axis('off')\n",
    "    axes[2][i].imshow(magno_cpu[i, 1].numpy(), cmap='gray')\n",
    "    axes[2][i].axis('off')\n",
    "axes[0][0].set_ylabel('RGB', fontsize=11)\n",
    "axes[1][0].set_ylabel('Magno ON', fontsize=11)\n",
    "axes[2][0].set_ylabel('Magno OFF', fontsize=11)\n",
    "fig.suptitle('RGBToMagno — 2-channel output', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## Section 6: SSL Replay & Seed Reproducibility\n",
    "\n",
    "1. **Seed reproducibility** — same seed produces identical output across separate runs\n",
    "2. **SSL replay** — `apply_last` replays identical params on a different view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream.transforms import (\n",
    "    RandomHorizontalFlip, RandomRotate, RandomGaussianBlur,\n",
    "    RandomColorJitterYIQ, Compose,\n",
    ")\n",
    "\n",
    "# Build the same pipeline twice with the same seed\n",
    "def make_pipeline(seed):\n",
    "    return Compose([\n",
    "        RandomHorizontalFlip(p=0.5, seed=seed, device=DEVICE),\n",
    "        RandomRotate(p=0.8, max_deg=30, seed=seed, device=DEVICE),\n",
    "        RandomGaussianBlur(p=0.5, kernel_size=7, sigma_range=(0.1, 2.0), seed=seed, device=DEVICE),\n",
    "        RandomColorJitterYIQ(p=1.0, hue=20, saturation=0.3, brightness=0.3, seed=seed, device=DEVICE),\n",
    "    ])\n",
    "\n",
    "# Run 1: seed=42\n",
    "pipe_a = make_pipeline(seed=42)\n",
    "out_a = pipe_a(images.clone())\n",
    "\n",
    "# Run 2: same seed=42, fresh pipeline\n",
    "pipe_b = make_pipeline(seed=42)\n",
    "out_b = pipe_b(images.clone())\n",
    "\n",
    "# Run 3: different seed\n",
    "pipe_c = make_pipeline(seed=123)\n",
    "out_c = pipe_c(images.clone())\n",
    "\n",
    "# Check\n",
    "same_seed_match = torch.equal(out_a, out_b)\n",
    "diff_seed_differ = not torch.equal(out_a, out_c)\n",
    "print(f\"seed=42 run1 vs seed=42 run2: identical={same_seed_match}\")\n",
    "print(f\"seed=42 vs seed=123: different={diff_seed_differ}\")\n",
    "\n",
    "n = min(4, len(images))\n",
    "fig, axes = plt.subplots(4, n, figsize=(n * 2.2, 8.5))\n",
    "for i in range(n):\n",
    "    axes[0][i].imshow(images[i].detach().cpu().clamp(0, 1).permute(1, 2, 0).numpy())\n",
    "    axes[0][i].axis('off')\n",
    "    axes[1][i].imshow(out_a[i].detach().cpu().clamp(0, 1).permute(1, 2, 0).numpy())\n",
    "    axes[1][i].axis('off')\n",
    "    axes[2][i].imshow(out_b[i].detach().cpu().clamp(0, 1).permute(1, 2, 0).numpy())\n",
    "    axes[2][i].axis('off')\n",
    "    axes[3][i].imshow(out_c[i].detach().cpu().clamp(0, 1).permute(1, 2, 0).numpy())\n",
    "    axes[3][i].axis('off')\n",
    "axes[0][0].set_ylabel('Original', fontsize=10)\n",
    "axes[1][0].set_ylabel('seed=42 (run 1)', fontsize=10)\n",
    "axes[2][0].set_ylabel('seed=42 (run 2)', fontsize=10)\n",
    "axes[3][0].set_ylabel('seed=123', fontsize=10)\n",
    "fig.suptitle(\n",
    "    f'Seed reproducibility: same seed → identical output (match={same_seed_match})\\n'\n",
    "    f'Different seed → different output (differ={diff_seed_differ})',\n",
    "    fontsize=13, fontweight='bold',\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream.transforms import RandomColorJitter, RandomColorJitterYIQ\n",
    "\n",
    "# Two different \"views\" of the same images (simulated with slight crops)\n",
    "view1 = images.clone()\n",
    "view2 = images.clone()  # In practice these would be different crops\n",
    "\n",
    "# t = RandomColorJitter(p=1.0, hue=20, saturation=0.3, value=0.3, brightness=0.3, contrast=0.3, seed=42, device=DEVICE)\n",
    "t = RandomColorJitter(p=1.0, hue=.4, saturation=0.3, value=0.3, contrast=0.3, seed=42, device=DEVICE)\n",
    "view1_aug = t(view1)          # samples new random params\n",
    "view2_aug = t.apply_last(view2)  # replays same params\n",
    "\n",
    "# Verify params are the same\n",
    "diff = (view1_aug - view2_aug).abs()\n",
    "print(f\"Max pixel diff between view1_aug and view2_aug: {diff.max().item():.6f}\")\n",
    "print(f\"(Should be 0.0 since same input + same params = same output)\")\n",
    "\n",
    "# Display: View1 Orig -> View1 Aug -> View2 Orig -> View2 Aug\n",
    "n = min(4, len(images))\n",
    "fig, axes = plt.subplots(4, n, figsize=(n * 2, 8.5))\n",
    "for i in range(n):\n",
    "    axes[0][i].imshow(view1[i].detach().cpu().clamp(0,1).permute(1, 2, 0).numpy())\n",
    "    axes[0][i].axis('off')\n",
    "    axes[1][i].imshow(view1_aug[i].detach().cpu().clamp(0,1).permute(1, 2, 0).numpy())\n",
    "    axes[1][i].axis('off')\n",
    "    axes[2][i].imshow(view2[i].detach().cpu().clamp(0,1).permute(1, 2, 0).numpy())\n",
    "    axes[2][i].axis('off')\n",
    "    axes[3][i].imshow(view2_aug[i].detach().cpu().clamp(0,1).permute(1, 2, 0).numpy())\n",
    "    axes[3][i].axis('off')\n",
    "axes[0][0].set_ylabel('View 1', fontsize=11)\n",
    "axes[1][0].set_ylabel('View 1 Aug', fontsize=11)\n",
    "axes[2][0].set_ylabel('View 2', fontsize=11)\n",
    "axes[3][0].set_ylabel('View 2 Aug', fontsize=11)\n",
    "fig.suptitle('SSL Replay: apply_last() replays identical color jitter\\n(same color shift visible on both views)', fontsize=13, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slipstream.transforms import RandomHorizontalFlip, Compose\n",
    "\n",
    "# Compose replay: flip + color jitter, replayed identically on view2\n",
    "aug = Compose([\n",
    "    RandomHorizontalFlip(p=0.5, seed=42, device=DEVICE),\n",
    "    # RandomColorJitterYIQ(p=1.0, hue=20, saturation=0.3, seed=42, device=DEVICE),\n",
    "    RandomColorJitter(p=1.0, hue=.4, saturation=0.3, value=0.3, contrast=0.3, seed=42, device=DEVICE)\n",
    "])\n",
    "\n",
    "view1_aug = aug(view1)             # forward pass: samples params\n",
    "view2_aug = aug(view2, replay=True)  # replay pass: same params\n",
    "\n",
    "diff = (view1_aug - view2_aug).abs()\n",
    "print(f\"Compose replay max diff: {diff.max().item():.6f} (should be 0.0)\")\n",
    "\n",
    "n = min(4, len(images))\n",
    "fig, axes = plt.subplots(2, n, figsize=(n * 2, 4.5))\n",
    "for i in range(n):\n",
    "    axes[0][i].imshow(view1_aug[i].detach().cpu().clamp(0,1).permute(1, 2, 0).numpy())\n",
    "    axes[0][i].axis('off')\n",
    "    axes[1][i].imshow(view2_aug[i].detach().cpu().clamp(0,1).permute(1, 2, 0).numpy())\n",
    "    axes[1][i].axis('off')\n",
    "axes[0][0].set_ylabel('View 1', fontsize=11)\n",
    "axes[1][0].set_ylabel('View 2 (replay)', fontsize=11)\n",
    "fig.suptitle('Compose replay: Flip + ColorJitter — identical augmentation on both views', fontsize=13, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
